---
ID: 40
-nombre: Explorar datos num√©ricos bivariados
"-tags:":
---
___
# Explorar datos num√©ricos bivariados
___
## 1- Introducci√≥n a las gr√°ficas de dispersi√≥n
___
### 1.1- Construir una gr√°fica de dispersi√≥n
___
![](https://www.youtube.com/watch?v=YHW1IfXssM8&t=173s)

- ***Variable dependiente***: En estad√≠stica es aquella que se estudia y se observa en un experimento o estudio para determinar c√≥mo cambia en respuesta a la manipulaci√≥n o cambio de otra variable. Tambi√©n se la conoce como "variable de respuesta" o "variable resultado". En una relaci√≥n causa-efecto, la variable dependiente es la que se espera que cambie como resultado de las variaciones en la variable independiente.
- ***Variable independiente***: Es aquella que se manipula o controla en un experimento o estudio. Es la variable que se cree que tiene un efecto sobre la variable dependiente. Tambi√©n se conoce como "variable de entrada" o "variable explicativa". La variable independiente se altera o var√≠a de forma intencionada para observar c√≥mo influye en la variable dependiente.

___
#### Ejercicios: Construir gr√°ficas de dispersi√≥n

___
- **Ejercicio 1:**
![[Pasted image 20230918100715.png|800]]

___
- **Ejercicio 2:**
![[Pasted image 20230918100847.png|800]]

___
- **Ejercicio 3:**
![[Pasted image 20230918101025.png|800]]

___
- **Ejercicio 4:**
![[Pasted image 20230918101220.png|800]]

___
#### Ejercicios: Hacer gr√°ficas de dispersi√≥n apropiadas

___
- **Ejercicio 1:**
![[Pasted image 20230918101502.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230918101751.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230918102119.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230918102315.png]]


___
### 1.2-  La direcci√≥n en gr√°ficas de dispersi√≥n. Ejemplo
![](https://www.youtube.com/watch?v=4ZZzL2tSftY&t=163s)

___
### 1.3- Gr√°fica de dispersi√≥n: fumadores
![](https://www.youtube.com/watch?v=BCCljPEL3f8&t=123s)

___
### 1.4- La linealidad, intensidad y direcci√≥n de una relaci√≥n bivariada
![](https://www.youtube.com/watch?v=4byfva5OPg8&t=671s)

Los **datos bivariados** se refieren a un conjunto de datos en el que se recopilan observaciones o mediciones de dos variables diferentes para cada elemento o individuo en un estudio o conjunto de datos. Estas dos variables est√°n relacionadas de alguna manera y se utilizan para analizar las posibles asociaciones o relaciones entre ellas.

En otras palabras, los datos bivariados son un tipo de datos en el que se recopilan pares de valores, donde un valor corresponde a una variable (llamada "variable X" o "``variable independiente``") y el otro valor corresponde a otra variable (llamada "variable Y" o "``variable dependiente``"). Cada par de valores representa una observaci√≥n o medici√≥n particular.

___
#### Ejercicios: Asociaciones lineales positivas y negativas a partir de gr√°ficas de dispersi√≥n

___
- **Ejercicio 1:**
![[Pasted image 20230918104024.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230918104152.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230918104304.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230918104337.png]]

___
#### Ejercicios: Describir tendencias en gr√°ficas de dispersi√≥n
___
- **Ejercicio 1:**
![[Pasted image 20230918104445.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230918104602.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230918104726.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230918104845.png]]

___
#### Ejercicios: Asociaciones positivas y negativas en gr√°ficas de dispersi√≥n
Hacemos gr√°ficas de dispersi√≥n para ver las asociaciones entre variables. Las gr√°ficas de dispersi√≥n son realmente buenos para ayudarnos a ver si dos variables tienen asociaci√≥n positiva o negativa (o ninguna correlaci√≥n en absoluto).
___
- **Ejercicio 1:**
![[Pasted image 20230918110359.png|700]]
![[Pasted image 20230918110456.png|700]]
![[Pasted image 20230918110533.png|700]]

___
- **Ejercicio 2:**
![[Pasted image 20230918110654.png|700]]
![[Pasted image 20230918110728.png|700]]


___
- **Ejercicio 3:**
![[Pasted image 20230918110816.png|700]]
![[Pasted image 20230918110902.png|700]]

___
### 1.5- Valores at√≠picos en gr√°ficas de dispersi√≥n
#### ¬øQu√© son los valores at√≠picos en las gr√°ficas de dispersi√≥n?
Las gr√°ficas de dispersi√≥n a menudo tienen un patr√≥n. Llamamos **valor at√≠pico** a un punto si este no se ajusta al patr√≥n.
![[Pasted image 20230918110952.png|500]]

Considera la gr√°fica de dispersi√≥n de arriba, que exhibe datos sobre algunos estudiantes en un viaje de mochileros (cada punto representa a un estudiante).

Observa como dos de los puntos no se ajustan muy bien al patr√≥n, y los hemos etiquetado como ``Brad y Sharon``, que son los nombres de los estudiantes a los que representan.

Sharon podr√≠a considerarse at√≠pica, porque est√° cargando una mochila mucho m√°s pesada de lo que predice el patr√≥n.

Brad podr√≠a considerarse at√≠pico, porque est√° cargando una mochila mucho m√°s ligera de lo que predice el patr√≥n.

**Idea clave:** No existe una regla especial que nos diga si un punto en una gr√°fica de dispersi√≥n es un valor at√≠pico o no. Al hacer estad√≠stica m√°s avanzada, puede ser √∫til inventar una definici√≥n precisa de "valor at√≠pico", pero todav√≠a no lo necesitamos.

___
- **Ejercicio 1:**
![[Pasted image 20230918111228.png|700]]

___
- **Ejercicio 2:**
![[Pasted image 20230918111526.png|700]]

___
### 1.6- Cl√∫steres en gr√°ficas de dispersi√≥n
#### ¬øQu√© son los cl√∫steres en las gr√°ficas de dispersi√≥n?
Algunas veces los puntos una gr√°fica de dispersi√≥n forman distintos grupos. Estos grupos se llaman **cl√∫steres.**

![[Pasted image 20230918111616.png]]

Considera la gr√°fica de dispersi√≥n que se muestra arriba, que exhibe la informaci√≥n nutricional de **16 marcas de hot dogs** en **1986** (cada punto representa una marca). Los puntos forman dos cl√∫steres, uno a la izquierda y el otro a la derecha.

El **cl√∫ster izquierdo** es aquel cuyas marcas tienden a ser bajas en calor√≠as y bajas en sodio (en color verde). El **cl√∫ster derecho** aquel cuyas marcas tienden a ser altas en calor√≠as y altas en sodio (en color azul).

___
- **Ejercicio 1:**
![[Pasted image 20230918111949.png|700]]

___
- **Ejercicio 2:**
![[Pasted image 20230918112124.png|700]]

___
### 1.7-  Describir gr√°ficas de dispersi√≥n (forma, direcci√≥n, intensidad, valores at√≠picos)
Al ver una gr√°fica de dispersi√≥n, deber√≠amos ser capaces de describir la asociaci√≥n que observamos entre las variables.

Una r√°pida descripci√≥n de la asociaci√≥n en una gr√°fica de dispersi√≥n siempre debe incluir una descripci√≥n de _la forma, la direcci√≥n_ y _la fuerza_ de la asociaci√≥n, junto con la presencia de _valores at√≠picos_.

_Forma:_ ¬øla asociaci√≥n es lineal o no lineal?

_Direcci√≥n:_ ¬øla asociaci√≥n es positiva o negativa?

_Fuerza:_ ¬øla asociaci√≥n parece ser fuerte, moderadamente fuerte o d√©bil?

_Valores at√≠picos:_ ¬øparecen haber datos inusualmente lejos del patr√≥n general?

Tambi√©n es importante incluir el contexto de las dos variables en la descripci√≥n de estas caracter√≠sticas. Aqu√≠ hay un ejemplo.
#### Ejemplo
Vamos a describir esta gr√°fica de dispersi√≥n, que muestra la relaci√≥n entre la **edad de los conductores** y el n√∫mero de **accidentes automovil√≠sticos por cada 100 conductores** en el a√±o **2009**.

![[Pasted image 20230918112338.png]]

Esta gr√°fica de dispersi√≥n presenta una **asociaci√≥n lineal fuerte y negativa** entre la **edad de los conductores** y el **n√∫mero de accidentes**. La relaci√≥n es claramente **negativa**, lo que significa que a medida que la edad de los conductores aumenta, el n√∫mero de accidentes tiende a disminuir de manera significativa. Adem√°s, no se observa la presencia de **valores at√≠picos** en los datos, lo que sugiere que la tendencia es consistente a lo largo del rango de edades analizado. Este patr√≥n proporciona informaci√≥n valiosa sobre la seguridad vial en el a√±o **2009**.
___
- **Ejercicio 1:**
![[Pasted image 20230918112453.png|700]]

___
- **Ejercicio 2:**
![[Pasted image 20230918112553.png|700]]


___
- **Ejercicio 3:**
![[Pasted image 20230918112625.png|700]]

___
## 2- Coeficientes de correlaci√≥n
___
### 2.1- Nociones sobre el coeficiente de correlaci√≥n. Ejemplo
![](https://www.youtube.com/watch?v=Ug7rikVd6qU&t=632s)

___
#### Ejercicios: Nociones sobre el coeficiente de correlaci√≥n

___
- **Ejercicio 1**:
![[Pasted image 20230918183033.png|700]]

___
- **Ejercicio 2**:
![[Pasted image 20230918183126.png|700]]

___
- **Ejercicio 3:**
![[Pasted image 20230918183207.png|700]]


___
- **Ejercicio 4:**
![[Pasted image 20230918183252.png|700]]

___
### 2.2- Calcular el coeficiente de correlaci√≥n r
![](https://www.youtube.com/watch?v=QfEm0Jm_Xvc&t=839s)

___
### 2.3- Repaso del coeficiente de correlaci√≥n
#### F√≥rmula

$$\color{orange}r=\frac{1}{n-1}\sum \begin{bmatrix}
\frac{x_{i}-\bar{x}}{S_{x}}
\end{bmatrix}\begin{bmatrix}
\frac{y_{i}-\bar{y}}{S_{y}}
\end{bmatrix}$$

#### ¬øQu√© es un coeficiente de correlaci√≥n?
El coeficiente de correlaci√≥n, $r$, mide la direcci√≥n y la fuerza de una relaci√≥n lineal. Calcular $r$ es bastante complejo, as√≠ que por lo general usamos la tecnolog√≠a para hacer los c√°lculos. Nos enfocamos en entender lo que $r$ dice acerca de una gr√°fica de dispersi√≥n.

Aqu√≠ hay algunos datos acerca de $r$:

- Siempre tiene un valor entre $-1$ y $1$.
- Las relaciones lineales positivas fuertes tienen valores de $r$ cercanos a $1$.
- Las relaciones lineales negativas fuertes tienen valores de $r$ cercanos a $-1$.
- Las relaciones d√©biles tienen valores de $r$ cercanos a $0$.

Veamos algunos ejemplos:

![[Pasted image 20230918184811.png|600]]
![[Pasted image 20230918184830.png|600]]
![[Pasted image 20230918184850.png|600]]
![[Pasted image 20230918184906.png|600]]
![[Pasted image 20230918184923.png|600]]

___
## 3- Introducci√≥n a las rectas de tendencia
___
### 3.1- Ajustar una recta a un conjunto de datos
___
![](https://www.youtube.com/watch?v=hsJEbsTuqq8)

___
### 3.2- Estimar la recta que mejor se ajusta a los datos. Ejercicio
![](https://www.youtube.com/watch?v=vV5HLWRYBXo&t=175s)

___
#### Ejercicios: Estimar la recta que mejor se ajusta "a ojo de buen cubero"

___
- **Ejercicio 1**:
![[Pasted image 20230918190329.png]]

___
- **Ejercicio 2**:
![[Pasted image 20230918190351.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230918190529.png]]

___
- **Ejercicio 4**:
![[Pasted image 20230918190515.png]]

___
### 3.3- Estimar con regresi√≥n lineal (modelos lineales)
![](https://www.youtube.com/watch?v=Eo9Yx-hVpLQ&t=355s)

___
#### Ejercicios: Estimar ecuaciones de rectas de mejor ajuste, y utilizarlas para hacer predicciones

___
- **Ejercicio 1**:
![[Pasted image 20230918191611.png]]

___
- **Ejercicio 2**:
![[Pasted image 20230918193016.png]]

___
- **Ejercicio 3:
![[Pasted image 20230918193311.png]]

___
- **Ejercicio 4**:
![[Pasted image 20230918194411.png]]

___
### 3.4- Recta de mejor ajuste: fumar en 1945
![](https://www.youtube.com/watch?v=itWelp3mTgY&t=406s)

___
#### Ejercicios: Estimar la pendiente de la recta de mejor ajuste
___
- **Ejercicio 1:**
![[Pasted image 20230919160848.png|700]]

___
- **Ejercicio 2:**
![[Pasted image 20230919161246.png|700]]

___
- **Ejercicio 3:**
![[Pasted image 20230919155846.png|700]]

___
- **Ejercicio 4**:**
![[Pasted image 20230919160242.png|700]]

___
#### Ecuaciones de rectas de tendencia: datos de tel√©fono
Paige recolect√≥ datos sobre cu√°nto tiempo pas√≥ en el tel√©fono en comparaci√≥n con cu√°nta bater√≠a le quedaba (en horas) en el d√≠a. Aqu√≠ est√°n los datos:

![[Pasted image 20230919161841.png]]

Luego hizo esta gr√°fica de dispersi√≥n:

![[Pasted image 20230919161858.png|500]]

Ahora ella quiere una recta de tendencia para describir la relaci√≥n entre el  tiempo pas√≥ en el tel√©fono y la bater√≠a restante. Ella dibuj√≥ tres posibles rectas de tendencia:

![[Pasted image 20230919161940.png|500]]

___
- **Ejercicio 1:**
![[Pasted image 20230919162019.png|500]]

___
- **Ejercicio 2**:
![[Pasted image 20230919162339.png|1000]]

___
- **Ejercicio 3:**
![[Pasted image 20230919162924.png]]

___
- **Ejercicio 4:
![[Pasted image 20230919163331.png]]


___
- **Ejercicio 5:
![[Pasted image 20230919163423.png]]


___
- **Ejercicio 6:**
![[Pasted image 20230919163614.png]]




___
- **Ejercicio 7:**
![[Pasted image 20230919163733.png]]


___
- **Ejercicio 8:**
![[Pasted image 20230919164147.png]]

___
## 4- Ecuaciones de regresi√≥n por m√≠nimos cuadrados
___
### 4.1- Introducci√≥n a los residuos y a la regresi√≥n por m√≠nimos cuadrados
![](https://www.youtube.com/watch?v=FvjfIjXSxBw&t=719s)

___
### 4.2- Introducci√≥n a los residuos
Nos enfrentamos con un problema cuando tratamos de ajustar una recta a un conjunto de datos en una gr√°fica de dispersi√≥n. El problema es este: es dif√≠cil asegurar cu√°l recta se ajusta mejor a un conjunto de datos.

Por ejemplo, imagina que tres cient√≠ficos, **Andrea**, **Jeremy**, y **Brooke**, est√°n trabajando con el mismo conjunto de datos. Si cada cient√≠fico dibuja una recta de ajuste diferente, ¬øC√≥mo deciden cu√°l recta se ajusta mejor?

![[Pasted image 20230919165614.png]]

Si tan solo tuvi√©ramos alguna forma de medir qu√© tan bien cada recta se ajusta a cada dato...

##### ¬°Residuos al rescate!
Un residuo es la medida de qu√© tan bien una recta se ajusta a un dato individual.

Considera este conjunto de datos con una recta de ajuste dibujada encima:

![[Pasted image 20230919165659.png|400]]

Y observa c√≥mo el punto $(2,8)$ est√° **4 unidades** por encima de la recta:

![[Pasted image 20230919165746.png|400]]

Esta distancia vertical se conoce como un **residuo**. Para datos por encima de la recta, el residuo es positivo, y para datos por debajo de la recta, el residuo es negativo.

Por ejemplo, el residuo para el punto $(4,3)$ es **-2**:

![[Pasted image 20230919165826.png|400]]

Entre m√°s cercano sea el residuo de un dato a **0**, mejor ser√° el ajuste. En este caso, la recta se ajusta al punto (4,3) mejor de lo que se ajusta al punto (2,8).


___
- **Ejercicio : Trata de encontrar los residuos restantes por ti mismo**

![[Pasted image 20230919170247.png]]


___
### 4.3- Ejemplo de calcular residuos
![](https://www.youtube.com/watch?v=1glphmdUXio&t=428s)

___
#### Ejercicios: Calcular e interpretar residuos

___
- **Ejercicio 1:**
![[Pasted image 20230919171238.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230919171438.png]]


___
- **Ejercicio 3:**
![[Pasted image 20230919171914.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230919172202.png]]

___
### 4.4- Calcular la ecuaci√≥n de una recta de regresi√≥n
![](https://www.youtube.com/watch?v=7R_169J0zIQ&t=550s)

___
#### Ejercicio: Calcular la ecuaci√≥n de la recta de m√≠nimos cuadrados
___
- **Ejercicio 1:**
![[Pasted image 20230920100100.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230920100853.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230920101519.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230920101944.png]]

___
### 4.5- Interpretar la pendiente de la recta de regresi√≥n
![](https://www.youtube.com/watch?v=kF3XmL7ubuo&t=292s)

___
### 4.6- Interpretar la ordenada al origen en el modelo de regresi√≥n
![](https://www.youtube.com/watch?v=l8uBEqe31Z0&t=268s)

___
### 4.7- Interpretar una recta de tendencia
![](https://www.youtube.com/watch?v=pO3kbiPPo6o&t=285s)

___
#### Ejercicios: Interpretar la pendiente y la ordenada al origen para modelos lineales

___
- **Ejercicio 1:**
![[Pasted image 20230920103012.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230920103216.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230920103531.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230920103725.png]]

___
## 5- Evaluar el ajuste en la regresi√≥n por m√≠nimos cuadrados
___
### 5.1- Gr√°ficas de residuos
![](https://www.youtube.com/watch?v=rN9VPYjTIUU&t=1s)

___
#### Ejercicios: Gr√°ficas de residuos

___
- **Ejercicio 1:**
![[Pasted image 20230920110723.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230920111341.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230920111502.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230920111618.png]]

___
### 5.2- Ideas intuitivas detr√°s de la R cuadrada
Cuando aprendimos sobre el coeficiente de correlaci√≥n, $r$, nos centramos en lo que significaba en lugar de c√≥mo calcularlo, ya que los c√°lculos son largos y generalmente las computadoras los resuelven por nosotros.

Vamos a hacer lo mismo con $r^2$ (squared) y concentrarnos en c√≥mo interpretar lo que significa. En cierto modo, $r^2$ mide qu√© tanto se elimina del error de predicci√≥n al usar la regresi√≥n por m√≠nimos cuadrados.

#### Predicciones sin usar regresi√≥n
Usamos la regresi√≥n lineal para predecir $y$ dado un valor de $x$. Pero supongamos que tenemos que predecir un valor de $y$ sin un valor correspondiente de $x$. Sin utilizar la regresi√≥n en la variable $x$, nuestra estimaci√≥n m√°s razonable ser√≠a simplemente predecir el **promedio** de los valores de $y$. Este es un ejemplo donde la recta de predicci√≥n es simplemente la **media** de los datos de $y$.

![[Pasted image 20230920111828.png]]

Observa que esta recta no parece ajustarse muy bien a los datos. Una forma de medir el ajuste de la recta es calcular la suma de los residuos al cuadrado, esto nos da un sentido general de cu√°nto error de predicci√≥n tiene un modelo dado.

![[Pasted image 20230920111858.png]]

As√≠ que sin la regresi√≥n por m√≠nimos cuadrados, la suma de los cuadrados es $41.1879$.

¬øUsar la regresi√≥n por m√≠nimos cuadrados reducir√≠a el error en la predicci√≥n? Si es as√≠, ¬øpor cu√°nto? ¬°Ve√°moslo!

#### Predicciones con el uso de la regresi√≥n
Aqu√≠ te presentamos los mismos datos con la recta de regresi√≥n por m√≠nimos cuadrados correspondiente y el resumen estad√≠stico:

![[Pasted image 20230920112036.png]]

![[Pasted image 20230920112045.png]]

Esta recta parece ajustar los datos bastante bien, pero para medir qu√© tanto mejor se ajusta, podemos fijarnos otra vez en la suma de los cuadrados de los residuos:

![[Pasted image 20230920112144.png]]

Al usar la regresi√≥n por m√≠nimos cuadrados, se redujo la suma de los cuadrados de los residuos de $41.1879$ a $13.7627$.

As√≠ que con la regresi√≥n por m√≠nimos cuadrados eliminamos una cantidad considerable del error de predicci√≥n. Pero, ¬øQu√© tanto?

#### La R cuadrada mide qu√© tanto error de predicci√≥n eliminamos
Sin usar la regresi√≥n, el modelo ten√≠a una suma total de cuadrados de $41.1879$. Mediante la regresi√≥n por m√≠nimos cuadrados, se redujo a $13.7627$. 

Por lo tanto, la reducci√≥n total es de $41.1879 - 13.7627 = 27.4252$.

Podemos representar esta reducci√≥n como un porcentaje de la cantidad original del error de predicci√≥n:

$$\frac{41.1879‚àí13.7627}{41.1879}=\frac{27.4252}{41.1879}‚âà66.59\%$$

Si te fijas m√°s arriba, ver√°s que $r^2 = 0.6659$. 
R-cuadrada nos dice qu√© porcentaje del error de predicci√≥n en la variable $y$ se elimina al usar la regresi√≥n por m√≠nimos cuadrados en la variable $x$. Como resultado, a $r^2$ tambi√©n se le llama coeficiente de determinaci√≥n.

En muchas definiciones formales, $r^2$ nos dice qu√© porcentaje de variabilidad en la variable $y$ est√° contabilizada por la regresi√≥n en la variable $x$.

Parece bastante notable que simplemente elevar $r$ al cuadrado nos d√© esa medida. Demostrar esta relaci√≥n entre $r$ y $r^2$ es bastante complejo y est√° fuera del alcance de un curso introductorio de estad√≠stica.

___
### 5.3- R cuadrada o coeficiente de determinaci√≥n
![](https://www.youtube.com/watch?v=rTm5ZMjIKzM&t=762s)

___
### 5.4- Desviaci√≥n est√°ndar de los residuos o ra√≠z del error cuadr√°tico medio (ECM)
![](https://www.youtube.com/watch?v=M0VgMg7jpRM&t=336s)

___
### 5.5- Interpretar datos de regresi√≥n por computadora
![](https://www.youtube.com/watch?v=oi4OEWHkNKc&t=267s)

___
#### Ejercicios: Interpretar los resultados de una regresi√≥n obtenidos por computadora

___
- **Ejercicio 1:**
Desiree est√° interesada en ver si los estudiantes que consumen m√°s cafe√≠na tienden a estudiar m√°s. Para esto, selecciona aleatoriamente 20 estudiantes de su escuela y registra su consumo de cafe√≠na (en mg) y el n√∫mero de horas que pasan estudiando. Una gr√°fica de dispersi√≥n de los datos muestra una relaci√≥n lineal.

Este es el resultado de un an√°lisis de regresi√≥n por m√≠nimos cuadrados de los datos realizado en una computadora:

![[Pasted image 20230922190133.png]]

![[Pasted image 20230922191133.png]]

![[Pasted image 20230922191403.png]]

![[Pasted image 20230922191608.png]]

![[Pasted image 20230922192026.png]]

![[Pasted image 20230922192155.png]]

![[Pasted image 20230922192508.png]]

___
### 5.6- El impacto de eliminar valores at√≠picos en las rectas de regresi√≥n
![](https://www.youtube.com/watch?v=rKQEBdbX3B4)

___
#### Ejercicios: Efectos de los puntos influyentes

___
- **Ejercicio 1:**
![[Pasted image 20230922192930.png]]

___
- **Ejercicio 2:**
![[Pasted image 20230922193245.png]]

___
- **Ejercicio 3:**
![[Pasted image 20230922193606.png]]

___
- **Ejercicio 4:**
![[Pasted image 20230922193727.png]]

___
## 6- M√°s sobre regresi√≥n
___
### 6.1- Error cuadr√°tico en la regresi√≥n lineal
![](https://www.youtube.com/watch?v=hXCQu2PzLvg&t=408s)

___
### 6.2- Demostraci√≥n de la minimizaci√≥n del error cuadr√°tico en la regresi√≥n lineal. Parte 1
![](https://www.youtube.com/watch?v=UxJRxv8_uNU&t=636s)

___
### 6.3- Demostraci√≥n de la minimizaci√≥n del error cuadr√°tico en la regresi√≥n lineal. Parte 2
![](https://www.youtube.com/watch?v=pcWAoUVBPQQ&t=595s)

___
### 6.4- Demostraci√≥n de la minimizaci√≥n del error cuadr√°tico en la regresi√≥n lineal. Parte 3
![](https://www.youtube.com/watch?v=56of81vus1U&t=656s)

___
### 6.5- Demostraci√≥n de la minimizaci√≥n del error cuadr√°tico en la regresi√≥n lineal. Parte 4
![](https://www.youtube.com/watch?v=jGUsGuj9reA)

___
### 6.6- Regresi√≥n lineal. Ejemplo
![](https://www.youtube.com/watch?v=FhRB0aWq3OI&t=568s)

___
### 6.7- Segunda regresi√≥n. Ejemplo
![](https://www.youtube.com/watch?v=HEKZl8aPM0M&t=556s)

___
### 6.8- Calcular la R cuadrada
![](https://www.youtube.com/watch?v=ki02iigSIK0&t=586s)

___
### 6.9- La covarianza y la regresi√≥n lineal
![](https://www.youtube.com/watch?v=rb6mcVfkDsE&t=909s)

___





















___
%%
V√≠nculos:
[[000-Men√∫ Estad√≠stica y probabilidadüìÉ|Men√∫ Estad√≠stica y probabilidadüìÉ]]

Tags:
#matem√°ticas #pagestad√≠stica_y_probabilidad
%%