---
ID: 152
"tags:": 
"nombre:": Clase 3 humai - Agrupaci칩n y Agregaci칩n
---
___
# Clase 3 humai - Agrupaci칩n y Agregaci칩n
___
![](https://www.youtube.com/watch?v=NFERQ_bCfHw&list=PLon--J7mANNWbXbGraiiMNWcv5T69kkAL&index=3)

___
## 1- Introducci칩n
En esta clase vamos a ver c칩mo agrupar datos a partir de una clave para trabajar sobre distintos grupos. El primer dataset que vamos a utilizar es del portal de datos abiertos de Espa침a. Los datos se pueden encontrar [aqu칤](https://colab.research.google.com/corgiredirector?site=http%3A%2F%2Fopendata.esri.es%2Fdatasets%2Fparo-por-municipio-espa%25C3%25B1a%2Fgeoservice) y la 칰nica modificaci칩n que se les hizo fue reemplazar el c칩digo de provincia por la descripci칩n de la misma

```python
! pip install plotly
```

```python
import pandas as pd
import plotly.express as px
```

```python
df = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/parodesprov.csv')
```

```python
df.sort_values('Codigo').head(6)
```
![[Pasted image 20230914201658.png]]

Noten que en este conjunto de datos, al parecer la base est치 duplicada. Los municipios figuran dos veces, una vez con el c칩digo de provincia en NaN y otra vez con el c칩digo de provincia informado. Los valores de paro y poblaci칩n son muy cercanos en todos los casos, as칤 que podemos considerarlas cercanas en el tiempo.

```python
df = df[df['PAD_1_COD_PROV'].notnull()].copy()

df.sort_values('Codigo').head(6)
```
$$Consola$$
![[Pasted image 20230914201943.png]]

## 2- Niveles de Agregaci칩n
Adem치s de los municipios (identificados por la variable C칩digo), tenemos dos niveles de agregaci칩n geogr치fica, la provincia (Cod_Prov) y la comunidad aut칩noma (Cod_CAA).

Veamos qu칠 valores toman y c칩mo se combinan.

```python
# 쮺u치ntos municipios tiene cada comunidad? 쮿ay alguno que no tenga CCAA asociada?
df['Cod_CCAA'].value_counts(dropna=False)
```
$$Consola$$
![[Pasted image 20230914202123.png]]

```python
# 쮺u치ntas CCAA hay?
len(df['Cod_CCAA'].unique())
```
$$Consola$$
![[Pasted image 20230914202227.png]]


```python
# 쮺u치ntos municipios tiene cada provincia? 쮿ay alguno que no tenga provincia asociada?
df['Cod_Prov'].value_counts(dropna=False)
```
$$Consola$$
![[Pasted image 20230914202411.png]]


```python
# 쮺u치ntas provincias hay?
len(df['Cod_Prov'].unique())
```
$$Consola$$
![[Pasted image 20230914202454.png]]


```python
# 쮿ay alguna provincia que tenga m치s de una CCAA asociada?
df[['Cod_CCAA','Cod_Prov']].drop_duplicates().sort_values('Cod_Prov')
```
$$Consola$$
![[Pasted image 20230914202607.png]]


## 3- Buscando valores nulos

Ahora queremos filtrar todas las filas del DataFrame que contengan alg칰n valor nulo, para analizar en detalle por qu칠 existe ese valor faltante y si vamos a querer completarlo o descartarlo.

El m칠todo ``df.isnull()`` devuelve un DataFrame del mismo tama침o que el original, pero en lugar de los valores devuelve True si hab칤a un NaN y False si no lo hab칤a.

```python
df.isnull().head(3)
```
$$Consola$$
![[Pasted image 20230914202758.png]]

#### Entendiendo el par치metro axis

A continuaci칩n vamos a reducir el DataFrame de m치s arriba a una serie, compuesta por Booleans que indican True si hay alg칰n valor nulo en la fila y False si no hay ninguno. La forma de reducir una serie de Booleanos es ``any()`` y el par치metro ``axis = 1`` indica que queremos reducir el DataFrame aplicando la funci칩n de manera horizontal, probando todos los valores del eje y.

```python
df[df.isnull().any(axis=1)]
```
$$Consola$$
![[Pasted image 20230914203030.png]]

Otro posible m칠todo para reucir es all as칤 que una forma equivalente de lograr lo mismo es:

```python
df[~(df.notnull().all(axis=1))]
```
$$Consola$$
![[Pasted image 20230914203143.png]]

쯈u칠 significar치 un TotalParoRegistrado nulo? :thinking: 쯉er치 equivalente a un paro de 0, algo que es posible que se de?

```python
df[df['TotalParoRegistrado'] == 0].sample(3)
```
$$Consola$$
![[Pasted image 20230914203304.png]]

Podr칤amos concluir que no, porque los municipios con paro igual a 0, informan 0. Entonces deber칤amos descartar el dato.

#### Entendiendo el par치metro inplace

Noten que la mayor parte de los m칠todos que trabajan sobre DataFrames devuelven objetos nuevos que si no los almacenamos en una variable se pierden. Cuando queremos que el DataFrame cambie a partir de una determinada acci칩n usamos el par치metro ``inplace=True``.

```python
df.dropna(inplace=True)
```

```python
df[~(df.notnull().all(axis=1))]
```
$$Consola$$
![[Pasted image 20230914203528.png]]

### Crear columnas

Contamos con los cambios de poblaci칩n de cada municipio ('PAD_1C02') y tambi칠n con el 치rea ('Shape__Area'). Con estas columnas podemos formar la densidad.

```python
# 춰Operaci칩n vectorizada!
df['Densidad'] = df['PAD_1C02'] / df['Shape__Area']
```

Tambi칠n sabemos la cantidad de personas desempleadas y con eso podemos formar la proporci칩n de paro.

```python
df['Proporcion_Paro'] = 맋f['TotalParoRegistrado'] / df['PAD_1C02']
```

```python
df.head(6)
```
$$Consola$$
![[Pasted image 20230914203853.png]]

## 4- Funciones de Agregaci칩n simple

![[Pasted image 20230914203921.png]]

Vamos a comprobar que la poblaci칩n total coincida (aproximadamente) con la [poblaci칩n de Espa침a.](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fwww.google.com%2Fsearch%3Fclient%3Dfirefox-b-e%26q%3Dpoblacion%2Bespana)

```python
df['PAD_1C02'].sum()
```
$$Consola$$
![[Pasted image 20230915221637.png]]

쮺u치l es el promedio de proporci칩n de paro en las autonom칤as de Espa침a?

```python
df['Proporcion_Paro'].mean()
```
$$Consola$$
![[Pasted image 20230915221741.png]]

Ejercicio: 쮺u치ntas autonom칤as est치n por encima de la media y cu치ntas est치n por debajo?

```python
proporcion_paro_media = df["Proporcion_Paro"].mean()
df[df['Proporcion_Paro'] > proporcion_paro_media]
```
$$Consola$$
![[Pasted image 20230915223559.png]]

```python
df[df['Proporcion_Paro'] < proporcion_paro_media]
```
$$Consola$$
![[Pasted image 20230915223632.png]]

쮺u치l es la mediana?
```python
df['Proporcion_Paro'].median()
```
$$Consola$$
![[Pasted image 20230915223738.png]]


Que la mediana sea menor a la media, significa que hay algunos valores llamativamente altos. Veamos un gr치fico para ver la distribuci칩n de esta variable.

```python
fig = px.histogram(df, x="Proporcion_Paro")
fig.show()
```
$$Consola$$
![[Pasted image 20230915224506.png]]

Y en cuanto al tama침o, 쮺u치l es la mediana de tama침o en las autonom칤as?

```python
mediana_area = df['Shape__Area'].median()
mediana_area
```
$$Consola$$
![[Pasted image 20230915224619.png]]

Si dividimos a las autonom칤as entre "grandes" (con un 치rea mayor que la mediana) y "chicas" (con un 치rea menor), 쮺u치l grupo tiene mayor proporci칩n de paro?

```python
df.query('Shape__Area > @mediana_area')['Proporcion_Paro'].mean()
```
$$Consola$$
![[Pasted image 20230915224803.png]]

```python
df.query('Shape__Area < @mediana_area')['Proporcion_Paro'].mean()
```
$$Consola$$
![[Pasted image 20230915224827.png]]

Entonces, mientras que en autonom칤as m치s grandes la proporci칩n de paro es 6.5%, en las m치s chicas es de 5.4%.

Ejercicio: calculen c칩mo es esta relaci칩n con respecto a la densidad.

```python
mediana_densidad = df["Densidad"].median()
mediana_densidad
```
$$Consola$$
![[Pasted image 20230915225758.png]]

```python
df.query("Densidad < @mediana_densidad")["Proporcion_Paro"].mean()
```
$$Consola$$
![[Pasted image 20230915225808.png]]

```python
df.query("Densidad > @mediana_densidad")["Proporcion_Paro"].mean()
```
$$Consola$$
![[Pasted image 20230915225819.png]]


## 5- Group By: Trabajando sobre grupos
Muchas veces necesitamos analizar m칠tricas, pero sobre agrupamientos de los datos. Por ejemplo, las autonom칤as se agrupan en provincias y podemos querer ver el desempe침o de cada provincia. O en lugar de analizar la densidad separando 칰nicamente por la mediana, podemos querer ver qu칠 pasa en cada percentil.

En Pandas las ope![[splitapplycombine.png]]raciones sobre grupos se pueden ver como una combinaci칩n de las operaciones Split Apply Combine.

![[splitapplycombine.png|900]]

En algunos casos la operaci칩n que aplicamos sobre el dataframe original reduce el tama침o del mismo, por ejemplo cuando devolvemos la media de cada grupo y otras veces no, por ejemplo cuando comparamos cada elemento del grupo contra un benchmark del mismo, por ejemplo si quisi칠ramos hacer un ranking por juego para grupos de jugadores.

## 6- Clases que se encargan de la Agregaci칩n en Pandas

### DataSetGroupBy

Veamos qu칠 devuelve pandas cuando agrupamos un dataset por una columna:

```python
df.groupby('PAD_1_COD_PROV')
```
$$Conosla$$
![[Pasted image 20230915230153.png]]

```python
df.groupby('PAD_1_COD_PROV')['Shape__Area']
```
$$Conosla$$
![[Pasted image 20230915230234.png]]

En lugar de recibir una lista o numpy array de grupos, recibimos un objeto del tipo DataFrameGroupBy. Ahora veamos cu치nto tarda en ejecutarse este m칠todo.

### Lazy Evaluation

```python
%%timeit
df.groupby('PAD_1_COD_PROV')
```
$$Consola$$
![[Pasted image 20230915230535.png]]

```python
%%timeit
a = list(df.groupby('PAD_1_COD_PROV'))
```
$$Consola$$
![[Pasted image 20230915230542.png]]

Hacer 칰nicamente la agrupaci칩n por c칩digo de provincia lleva 50 microsegundos pero si convertimos el resultado a una lista, forzamos a que efectivamente se separen los grupos y eso tarda 10.9 ms.

Este comportamiento se llama "lazy evaluation" y es muy importante en todos los motores de procesamiento de datos. Ejecutar las operaciones computacionalmente pesadas, s칩lo cuando se necesita permite hacer los procesos m치s eficientes.

```python
a = list(df.groupby('PAD_1_COD_PROV'))
type(a[0])
```
$$Consola$$
![[Pasted image 20230915230723.png]]


```python
type(a[0][0])
```
$$Consola$$
![[Pasted image 20230915230727.png]]


```python
type(a[0][1])
```
$$Consola$$
![[Pasted image 20230915230733.png]]

### Iterar sobre los grupos

Podemos recorrer los grupos en un loop for, desempaquetando la tupla que contiene el nombre del grupo y el DataFrame correspondiente.

Veamos a ver cu치ntas autonom칤as tiene cada provincia.

```python
for (cod_prov, group) in df.groupby('PAD_1_COD_PROV'):
  print("provincia={0}, tama침o={1}".format(cod_prov, group.shape[0]))
```
$$Consola$$
![[Pasted image 20230915230932.png]]


## 7- SeriesGroupBy
Veamos el tipo de objeto que se forma cuando tomamos una serie del DataFrame.

```python
type(df.groupby('PAD_1_COD_PROV')['Proporcion_Paro'])
```
$$Consola$$
![[Pasted image 20230915231156.png]]

Es un objeto de tipo SeriesGroupBy. A estos objetos, podemos aplicarles cualquier funci칩n de agregaci칩n.

```python
%%time
df.groupby('PAD_1_COD_PROV')['Proporcion_Paro'].mean()
```
$$Consola$$
![[Pasted image 20230915231311.png]]

Noten que en este caso, la operaci칩n sobre el objeto SeriesGroupBy tarda (en este caso, va a depender del hardware) casi 15 veces que el loop for sobre el GroupBy. Esto es gracias a la vectorizaci칩n que vimos en la clase 1.

```python
a = df.groupby('PAD_1_COD_PROV')['Proporcion_Paro'].mean()
```


```python
# El resultado de una funci칩n de agregaci칩n sobre una SeriesGroupBy, es otra serie
type(a)
```
$$Consola$$
![[Pasted image 20230915231456.png]]

```python
# El 칤ndice de la serie son todas las provincias.
a.index
```
$$Consola$$
![[Pasted image 20230915231521.png]]

Ahora podemos probar otras funciones de agregaci칩n, por ejemplo calculemos el 치rea por provincia:

```python
df.groupby('PAD_1_COD_PROV')['Shape__Area'].sum()
```
$$Consola$$
![[Pasted image 20230915231639.png]]

## 8- Agregaciones m칰ltiples

Veamos ahora quiero combinar para cada provincia, cu치l es el 치rea, cu치l es la poblaci칩n, cu치l es la media y la mediana de paro y cu치ntas autonom칤as la componen. Para esto existe la funci칩n aggregate. Aplicada sobre un DataFrameGroupBy recibe como par치metro un diccionario con las nombres de columnas como claves y el tipo de agregaci칩n a realizar como valores. Pueden ser valores 칰nicos o listas con varios valores.

```python
df.groupby('PAD_1_COD_PROV').aggregate({'Shape__Area':'sum',
                    'PAD_1C02':'sum',
                    'Proporcion_Paro':['mean','median','size']}).head()
```
$$Consola$$
![[Pasted image 20230915231754.png]]

## 9- MultiIndex
 
```python
df_agregado.columns
```
$$Consola$$


#### Entendiendo la funci칩n pd.qcut

Tambi칠n podemos agrupar por m치s de una columna, usando una lista en lugar de un 칰nico valor como par치metro del groupby.

Calculemos los deciles de paro registrado en los distintos municipios. Para eso vamos a construir una columna que contenga el decil que ocupa el municipio en el ranking de proporci칩n de paro. El decil 1 va a representar las autonom칤as que mejor se desempe침an y el decil 10 las que peor lo hacen.

```python
df['Decil_Paro'] = pd.qcut(df['Proporcion_Paro'], 10, labels=range(1,11))
```


Ahora podemos agrupar por provincia y decil para ver cu치ntos municipios de cada decil hay en cada provincia.

```python
serie_prov_decil = df.groupby(['PAD_1_COD_PROV','Decil_Paro']).size()
```

```python
type(serie_prov_decil)
```
$$Consola$$
![[Pasted image 20230915232221.png]]

```python
serie_prov_decil.index
```
$$Consola$$
![[Pasted image 20230915232252.png]]

```python
serie_prov_decil.head(10)
```
$$Consola$$
![[Pasted image 20230915232321.png]]

El objeto MultiIndex puede ser complicado para trabajar. Por eso conviene utilizar el m칠todo reset_index() para volver a un DataFrame com칰n.

```python
df_prov = serie_prov_decil.reset_index()
```

```python
df_prov.head()
```
$$Consola$$
![[Pasted image 20230915232440.png]]

### Ejercicios

Ahora vamos a querer trabajar a nivel de provincia. Calculen la densidad, la proporci칩n de paro y la cantidad de municipios para cada provincia 쮺u치l es la provincia con mayor proporci칩n de paro? 쮺u치l es la que tiene menos?

```python
df.groupby('PAD_1_COD_PROV').aggregate({
  'Densidad':'mean',
  'Codigo':'count',
  'Proporcion_Paro':"mean"
  }).head()
```
$$Consola$$
![[Pasted image 20230916203750.png]]





























___
%%
tags: #programaci칩n #pagan치lisis_de_datos #python  #an치lisis_de_datos

V칤nculos:   [[000-Men칰 An치lisis de datos 游늮|Men칰 An치lisis de datos 游늮]] 
%%