---
ID: "030"
tags:
  - "#pagmachine_learning"
  - "#python"
nombre: Introducci칩n a ML y Regresi칩n Lineal Simple
---
___
# Introducci칩n a ML y Regresi칩n Lineal Simple
<a href="https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/MachineLearning/1_Introduccion/rls.ipynb"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>
## 쯈u칠 es Machine Learning?
![](https://www.youtube.com/watch?v=FuIlgsbPr9E&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=1)

## Overview del proceso
![](https://www.youtube.com/watch?v=K_HH8MoKQls&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=2)

## Algoritmos
![](https://www.youtube.com/watch?v=TrsdgvZHFhM&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=3)

## Modelos
![](https://www.youtube.com/watch?v=0L0bxq87c1Y&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=4)

## Regresi칩n Lineal Simple (RLS)
![](https://www.youtube.com/watch?v=RxbGnNCUIXk&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=5)

![](https://www.youtube.com/watch?v=oWAiy4m1wp8&list=PLISuMnTdVU-zF4QLEKnLvNVHb7N_wHCp0&index=6)


La RLS, es la aproximaci칩n m치s simple al aprendizaje supervisado. En particular, la regresi칩n lineal es una herramienta 칰til para predecir una respuesta cuantitativa.

Es un m칠todo que tiene muchos a침os y est치 presente en toda la bibliograf칤a.

Aunque parezca super simple comparado con las t칠cnicas modernas de machine learning, la regresi칩n lineal a칰n es un m칠todo 칰til y ampliamente usado.

Principalmente, sirve como un buen punto de partida para aproximaciones m치s nuevas: muchas de las t칠cnicas **fancy** pueden interpretarse como generalizaciones o extensiones de la regresi칩n lineal.

Por lo tanto es s칰per importante tener una buena compresi칩n de la regresi칩n lineal antes de estudiar los algoritmos m치s complejos de machine learning.

  
### Dataset Advertising

Supongamos que somos consultores estad칤sticos, y nos contratan con el objetivo de aumentar las ventas de un determinado producto.

El dataset Advertising consiste en las ventas del producto en 200 mercados, y el presupuesto dedicado en publicidad en 3 medios: TV, radio y diario.

Si logramos identificar una relaci칩n entre la inversi칩n en publicidad y las ventas, podremos recomendarle a nuestro cliente hacia d칩nde debe dirigir su inversi칩n en publicidad.

La variables predictoras ser치n los presupuestos para cada canal y la variable de respuesta ser치 las ventas.

<u>Exploremos un poco los datos:</u>


```python

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import statsmodels.api as sm

plt.rcParams["figure.figsize"] = (20,5)

```


```python

df = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/advertising.csv')

```


```python

df.head()

```

  

<div>

<style scoped>

  .dataframe tbody tr th:only-of-type {

    vertical-align: middle;

  }

  

  .dataframe tbody tr th {

    vertical-align: top;

  }

  

  .dataframe thead th {

    text-align: right;

  }

</style>

<table border="1" class="dataframe">

 <thead>

  <tr style="text-align: right;">

   <th></th>

   <th>TV</th>

   <th>Radio</th>

   <th>Newspaper</th>

   <th>Sales</th>

  </tr>

 </thead>

 <tbody>

  <tr>

   <th>0</th>

   <td>230.1</td>

   <td>37.8</td>

   <td>69.2</td>

   <td>22.1</td>

  </tr>

  <tr>

   <th>1</th>

   <td>44.5</td>

   <td>39.3</td>

   <td>45.1</td>

   <td>10.4</td>

  </tr>

  <tr>

   <th>2</th>

   <td>17.2</td>

   <td>45.9</td>

   <td>69.3</td>

   <td>12.0</td>

  </tr>

  <tr>

   <th>3</th>

   <td>151.5</td>

   <td>41.3</td>

   <td>58.5</td>

   <td>16.5</td>

  </tr>

  <tr>

   <th>4</th>

   <td>180.8</td>

   <td>10.8</td>

   <td>58.4</td>

   <td>17.9</td>

  </tr>

 </tbody>

</table>

</div>

  
  
Veamos la relaci칩n entre las ventas y la publicidad en cada uno de los medios


```python

fig, (ax1, ax2, ax3) = plt.subplots(1, 3)

df.plot.scatter(x='TV', y='Sales', ax=ax1)

df.plot.scatter(x='Radio', y='Sales', ax=ax2)

df.plot.scatter(x='Newspaper', y='Sales', ax=ax3);

```
  
  
![[output_6_0.png]]
  

Pensemos en estos datos. Algunas preguntas que podr칤an surgir:

<ul>

<li>쮿ay alguna relaci칩n entre el presupuesto en publicidad y las ventas?</li>

<li>쯈u칠 tan fuerte es esa relaci칩n?</li>

<li>쮺u치les de los medios mencionados contribuyen a las ventas?</li>

<li>쮺on cu치nta precisi칩n podemos predecir las ventas futuras?</li>

<li>쮼s esta relaci칩n lineal?</li>

</ul>

Resulta que la regresi칩n lineal puede ser usada para responder cada una de estas preguntas y algunas m치s.

Veamos algunos conceptos y luego intentaremos responderlas.

La regresi칩n lineal simple intenta predecir una respuesta cuantitativa Y en base a una 칰nica variable predictora X.

Asume que hay aproximadamente una relaci칩n lineal entre X e Y.


Matem치ticamente: $$ Sales \approx \hat {\beta}_{0} + \hat {\beta}_{1} TV $$

洧띻0 y 洧띻1 son dos constantes que representan el intercepto y la pendiente en el modelo lineal.

Juntos, 洧띻0 y 洧띻1 son conocidos como los **par치metros del modelo**.

Una vez que hemos usado nuestro set de entrenamiento para producir los estimadores   y  맗ara los coeficientes del modelo, podemos predecir futuras ventas en base a un valor particular de TV.

### 쮺칩mo calculamos los par치metros del modelo?

Vamos a elegir el par 洧띻0 y 洧띻1 tales que minimizan la distancia entre la l칤nea recta y los verdaderos valores que observamos:

<img src="https://i.ibb.co/8c2zbDy/mco.png" alt="Girl in a jacket" width="80%">
Ahora con Python:


```python

from sklearn.linear_model import LinearRegression

```


```python

#Mi modelo ser치 una instancia de la clase LinearRegression (춰Recuerden Programaci칩n Orientada a Objetos!)

model = LinearRegression(fit_intercept=True)

```


```python

# Definimos la "X" y la "y" con las que vamos a entrenar nuestro modelo

X = df.loc[:,['TV']]

y = df['Sales']

```

Noten que alrededor de tv hay dos corchetes, mientras que alrededor de Sales hay uno s칩lo.

Miren lo siguiente:


```python

type(X)

```
  pandas.core.frame.DataFrame
  
  

```python

type(y)

```


  pandas.core.series.Series


```python

X.shape

```


  (200, 1)

  
 

```python

y.shape

```


  (200,)

  
En scikit learn las variables explicativas se expresan en un DataFrame y la variable explicada es siempre una serie.


```python

#Los coeficientes (Betas) del modelo todav칤a no est치n definidos

model.coef_

```

  ---------------------------------------------------------------------------

  

  AttributeError              Traceback (most recent call last)

  

  <ipython-input-12-a43f8fe38395> in <module>

     1 #Los coeficientes (Betas) del modelo todav칤a no est치n definidos

  ----> 2 model.coef_

  

  AttributeError: 'LinearRegression' object has no attribute 'coef_'

  
  
```python

# Usamos el m칠todo fit para entrenar el modelo

```


```python

model.fit(X,y)

```



  LinearRegression()


```python

model.coef_

```


  array([0.05546477])



```python

model.intercept_

```

 

  6.974821488229891

 
<strong> 쮺칩mo interpretamos estos coeficientes? </strong>

$\hat {\beta}_{0} = 6.9748214882298925$

Este coeficiente indica que cuando la publicidad en TV es de 0, de todas maneras las ventas son de 6.97 unidades.

$\hat {\beta}_{1} = 0.05546477$

Este coeficiente indica que cuando agregamos 1 unidad de publicidad en TV, las ventas aumentan en 0.05 unidades.


### Ejercicio

쮺u치ntas ventas esperar칤amos con una inversi칩n en televisi칩n de 4 unidades?


```python

  ventas_estimadas = model.intercept_ +4 * model.coef_

print(ventas_estimadas)

```
![[Pasted image 20230925093222.png]]
  
```python

  model.predict([[4]])

```
![[Pasted image 20230925093231.png]]

## Precisi칩n de los coeficientes estimados

La matem치tica que soporta la regresi칩n lineal simple, se basa en suponer que la variable explicativa (X) y la explicada (y) guardan una relaci칩n lineal perfecta perturbada por **ruido aleatoreo**: fen칩menos que no podemos o no queremos explicar dentro del modelo y que no dependen de X.

Los fen칩menos del mundo real nunca son exactamente as칤, pero vamos a encontrar que esta simplificaci칩n es 칰til en muchos casos para, por ejemplo, estudiar la relaci칩n entre X e y.

Lo bueno de Python es que podemos simular datos que s칤 cumplen estrictamente este supuesto de linealidad + ruido aleatoreo y observar qu칠 pasa con las desviaciones estad칤sticas.

Supongamos que el precio de los departamentos de una ciudad es de 10000usd de base + usd2000/m2 m치s una perturbaci칩n aleatoria. Nuestra ciudad est치 compuesta por 1000 departamentos.

Vamos a simular esa poblaci칩n:


```python

# Las superficies de los departamentos se distribuyen normalmente y

# tienen una media de 100 mts2 con un desv칤o est치ndar de 20mts2

superficies = np.random.normal(loc=100, scale=20, size=1000).astype(int)

print(superficies[0:30])

```

  [105 88 125 118 82 93 74 100 93 88 80 93 86 118 72 100 87 97

  115 110 147 111 64 105 55 107 105 90 99 87]


```python

# Los errores aleatorios tienen un promedio de $0 y un desv칤o est치ndar de usd3000

errores = np.random.normal(loc=0, scale=80000, size=1000).astype(int)

print(errores[0:30])

```

  [ -58834  53157 -24508 -39528  46024 -107829 -133710 -35716  61181

  -113296  48593  -4342 -62496 -11345 -33901 -79241  25659  95611

   107103  76591  40854 148714 -98784 -58569 -93924  18288  29470

   143169  3253 -91451]

  
```python

# Generamos nuestra "poblaci칩n" de 1000 departamentos

precios_departamentos = (superficies * 2000 + 10000 + errores).astype(int)

print(precios_departamentos[0:30])

```


  [161166 239157 235492 206472 220024 88171 24290 174284 257181 72704

  218593 191658 119504 234655 120099 130759 209659 299611 347103 306591

  344854 380714 39216 161431 26076 242288 249470 333169 211253 92549]

  
Ahora supongamos que somos un grupo de relevadoras de precios y esa poblaci칩n es completamente desconocida para nosotras. Tenemos la posiblidad de tocar el timbre a algunos vecinos de la ciudad y preguntarles cu치nto pagaron por su casa, pero esto nos cuesta tiempo y esfuerzo.

Nos preguntamos entonces:


* Dada una casa de 100mts2 쮺u치l es su precio? 쮺u치nta confianza puedo tener en ese valor? 쯏 dada una casa de 500mts2?

* 쯇uedo afirmar con X% de confianza, que a mayor n칰mero de mts2 mayor precio?

* 쮺u치ntas casas tenemos que conocer para poder estimar los precios con un X% de confianza?

* 쮺u치ntas casas tenemos que conocer para entender cu치nto influyen los mts2 en el precio con un X% de confianza?

Todas estas preguntas se pueden responder si suponemos que en nuestra poblaci칩n se cumplen los supuestos de la regresi칩n lineal (vamos a entrar en detalle en la pr칩xima clase) y aplicamos t칠cnicas estad칤sticas.

### 1. La confianza en las predicciones

쯈u칠 pasa si tomamos una muestra de 30 departamentos? 쮺칩mo se ver칤a nuestra regresi칩n?

  
```python

df_poblacion = pd.DataFrame({'superficies':superficies,'precios':precios_departamentos})

  

df_muestra = df_poblacion.sample(30)

```

  
```python

model.fit(df_muestra[['superficies']],df_muestra['precios'])

```


  LinearRegression()


```python

coeficiente = model.coef_

print(coeficiente)

```

  [2007.41983563]


```python

f'Seg칰n el modelo que podemos construir con esta muestra, por cada mts2 de superficie, el precio aumenta ${coeficiente[0]}'

```



  'Seg칰n el modelo que podemos construir con esta muestra, por cada mts2 de superficie, el precio aumenta $2007.419835631704'



쯈u칠 pasa si tomamos otra muestra?


```python

df_muestra = df_poblacion.sample(30)

model.fit(df_muestra[['superficies']],df_muestra['precios'])

print(model.coef_)

```

  [3332.33534397]

Ahora tomemos 100 muestras y vamos a graficarlas. Tambi칠n veamos en rojo la verdadera funci칩n generadora de los datos:

precio_venta = 10000 + 2000 * superficia

  
```python

for i in range(100):

  # Tomamos una muesta de 30 departamentos

  df_muestra = df_poblacion.sample(30)

  # Entrenamos el modelo sobre la muestra

  model.fit(df_muestra[['superficies']],df_muestra['precios'])

  # Utilizamos al modelo para predecir los valores de todos los departamentos

  predicciones = model.predict(df_poblacion[['superficies']])

  # Graficamos cada una de las 100 regresiones

  plt.plot(df_poblacion['superficies'],predicciones,color='blue',alpha=0.1)

  

proceso_generador_perfecto = 10000 + df_poblacion['superficies'] * 2000

plt.plot(df_poblacion['superficies'],proceso_generador_perfecto,color='red')

plt.show()

```

  ![[output_39_0.png]]
  
Todas las regresiones son distintas, pero las predicciones se parecen mucho m치s alrededor de 100 que en los extremos Recuerdan cu치l era la superficie promedio de los departamentos en nuestra ciudad?

#### Conclusi칩n 1
Las predicciones son m치s precisas cerca del centroide de los datos que en los extremos. En otras palabras, nuestro modelo conoce bien lo que vio y m치s all치 de eso, s칩lo puede hacer extrapolaciones cada vez m치s imprecisas.

쯈u칠 pasa si en lugar de 30, tomamos muestras m치s grandes? Es decir, aunque cueste m치s esfuerzo hacemos un relevamiento m치s exahustivo...


```python

for i in range(100):

  # Ahora tomamos una muesta de 150 departamentos

  df_muestra = df_poblacion.sample(150)

  # Entrenamos el modelo sobre la muestra

  model.fit(df_muestra[['superficies']],df_muestra['precios'])

  # Utilizamos al modelo para predecir los valores de todos los departamentos

  predicciones = model.predict(df_poblacion[['superficies']])

  # Graficamos cada una de las 100 regresiones

  plt.plot(df_poblacion['superficies'],predicciones,color='blue',alpha=0.1)

  

proceso_generador_perfecto = 10000 + df_poblacion['superficies'] * 2000

plt.plot(df_poblacion['superficies'],proceso_generador_perfecto,color='red')

plt.show()

```


![png](output_41_0.png)

#### Conclusi칩n 2

Si tomamos muestras m치s grandes, las regresiones son todas m치s parecidas entre s칤.

La interpretaci칩n estad칤stica de esta incerteza en las predicciones, est치 dada por los intervalos de confianza.

Algunas librer칤as de Python permiten calcular los intervalos de confianza de un modelo. No es el caso de scikit learn porque esta librer칤a est치 pensada para machine learning en general, no s칩lo para regresiones y busca crear una interfaz com칰n para todos los modelos.

Para acceder a estimaciones estad칤sticas como los intervalos de confianza, en el pr칩ximo encuentro vamos a utilizar statsmodel.



___

%%
tags: #pagmachine_learning #python   

V칤nculos: [[000-Men칰 Machine Learning 游늮|Men칰 Machine Learning 游늮]] 
%%