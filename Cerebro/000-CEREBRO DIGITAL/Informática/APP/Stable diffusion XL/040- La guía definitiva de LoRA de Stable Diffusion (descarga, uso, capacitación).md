---
ID: 40
-nombre: La gu√≠a definitiva de LoRA de Stable Diffusion (descarga, uso, capacitaci√≥n)
"-tags:":
---
___
# La gu√≠a definitiva de LoRA de Stable Diffusion (descarga, uso, capacitaci√≥n)
Los LoRA (adaptaciones de bajo rango) son archivos m√°s peque√±os (entre 1 MB y 200 MB) que se combinan con modelos de [Stable Diffusion checkpoint models](https://aituts.com/models/) existentes para **introducir nuevos conceptos** **en sus modelos** , de modo que su modelo pueda generar estos conceptos.

Estos nuevos conceptos se dividen en 2 categor√≠as: **temas(subject)** y **estilos(styles)** .

Los temas pueden ser cualquier cosa, desde personajes ficticios hasta personas de la vida real, expresiones faciales, poses, accesorios, objetos y entornos.

Los estilos incluyen [visual aesthetics](https://aesthetics.fandom.com/wiki/List_of_Aesthetics) , estilos de arte  y estilos art√≠sticos.

LoRA fue desarrollado por Microsoft Research en 2021 [ [Papel](https://arxiv.org/pdf/2106.09685.pdf) ][ [Github](https://github.com/microsoft/LoRA) ].

**Datos breves** :

- Ajustar los modelos de IA para realizar tareas espec√≠ficas puede resultar lento y dif√≠cil. LoRA se cre√≥ como una forma m√°s r√°pida y eficiente de ajustar modelos de lenguaje grandes y luego se adapt√≥ a modelos de difusi√≥n para la generaci√≥n de im√°genes.
- Los LoRA han ganado popularidad porque tienen menores requisitos de hardware para la capacitaci√≥n y su peque√±o tama√±o los hace f√°ciles de compartir y descargar.
- Puedes [entrenar tu propio LoRA](https://aituts.com/wp-admin/post.php?post=5309&action=edit#training) con tan solo 10 im√°genes de entrenamiento
- Debes entrenar tu LoRA sobre un [modelo b√°sico/fundamental](https://www.adalovelaceinstitute.org/resource/foundation-models-explainer/#:~:text=Foundation%20models%20are%20AI%20models,base'%20for%20many%20other%20applications.) :
    - Los LoRA m√°s realistas de la actualidad est√°n entrenados en Stable Diffusion v1.5 (o modelos basados ‚Äã‚Äãen √©l)
    - La mayor√≠a de los LoRA de anime/dibujos animados/estilizados de hoy en d√≠a est√°n entrenados en NAI Diffusion (o modelos basados ‚Äã‚Äãen √©l)
    - La pr√≥xima generaci√≥n de LoRA se entrenar√° en [SDXL](https://aituts.com/sdxl/)

**Uso r√°pido:**

- [Los usuarios de AUTOMATIC1111](https://aituts.com/stable-diffusion-on-windows-automatic1111/) pueden usar LoRA descarg√°ndolos y coloc√°ndolos en la carpeta `stable-diffusion-webui/models/Lora`y luego agregando la frase `<lora:LORA-FILENAME:WEIGHT>` a su mensaje, donde ``LORA-FILENAME`` es el nombre de archivo del LoRA sin la extensi√≥n de archivo, y ``WEIGHT``(que toma un valor de 0-1) es la fuerza de la LoRA
- A veces, los LoRA tienen palabras desencadenantes que debes usar en el mensaje adem√°s de la frase clave anterior.
- Puede utilizar tantos LoRA en el mismo mensaje como desee

En esta gu√≠a, cubriremos brevemente qu√© es un LoRA, c√≥mo se compara con otras t√©cnicas de ajuste, mostraremos algunos LoRA populares, le mostraremos c√≥mo ejecutarlos y, finalmente, le mostraremos c√≥mo entrenar uno.

Esta es la parte 4 de la serie Difusi√≥n estable para principiantes:

## ¬øQu√© son las LoRA?

Un LoRA es un tipo de m√©todo de entrenamiento para **ajustar** modelos de Stable Diffusion.

¬øQu√© es el fine-tuning?

Digamos que queremos entrenar un modelo de imagen para generar im√°genes a nuestra semejanza.

Entrenar un modelo desde cero ser√° extremadamente costoso y prohibitivo para la mayor√≠a de las personas.

En lugar de entrenar un nuevo modelo desde cero **,** podemos **reutilizar uno existente como punto de partida** . Podemos tomar un modelo como Stable Diffusion v1.5 y entrenarlo en un conjunto de datos mucho m√°s peque√±o (las im√°genes de nosotros), creando un modelo que sea simult√°neamente bueno en la tarea amplia de generar im√°genes realistas y en la tarea limitada de generar im√°genes de nuestro semejanza.

### LoRA y Dreambooth

Dreambooth es otra t√©cnica de ajuste que te permite entrenar a tu modelo en un concepto como un personaje o estilo. En la pr√°ctica, Dreambooth y LoRA est√°n destinados a lograr lo mismo.

La diferencia es que Dreambooth _actualiza_ todo el modelo, pero LoRA genera un peque√±o archivo _externo_ al modelo.

Esto significa que el entrenamiento de Dreambooth producir√° un modelo de punto de control completo (esta es una de las principales formas en que las personas crean [modelos personalizados](https://aituts.com/models/) ), pero los archivos LoRA deben usarse _en combinaci√≥n_ con un modelo de punto de control existente.

En t√©rminos de calidad, un LoRA bien entrenado es comparable a un modelo Dreambooth. LoRA tiene la ventaja de un _proceso de entrenamiento mucho_ m√°s r√°pido, menores requisitos de GPU y resultados m√°s peque√±os.

### LoRA vs Hypernetwork
[Las hiperredes](https://aituts.com/hypernetworks/) funcionan casi exactamente igual que LoRA. Tambi√©n son archivos m√°s peque√±os que se utilizan con modelos de puntos de control para presentar nuevos conceptos a sus generaciones.

La diferencia es t√©cnica: tanto las hiperredes como las LoRA cambian de valores a medida que pasan por las [capas de atenci√≥n](https://jalammar.github.io/illustrated-stable-diffusion/) del modelo, sin embargo, lo hacen de manera diferente.

Puede considerarlos como "LoRA heredados" porque en gran medida se han vuelto obsoletos.

Sin embargo, si tienes una hiperred que usas y disfrutas, no hay raz√≥n para dejar de usarla.

### LoRA vs Textual Inversion
LoRA y Dreambooth est√°n destinados a ense√±arle a un modelo un _nuevo_ concepto.

**[Textual Inversion/Embeddings](https://aituts.com/textual-inversion/)** Por otro lado, utiliza elementos que el modelo ya conoce para crear el resultado deseado. Son m√°s bien ayudantes r√°pidos que cualquier otra cosa.

Usemos caras como ejemplo. Cuando usamos una inversi√≥n textual para generar una cara, el modelo no genera una cara "nueva".

En cambio, nuestra inversi√≥n textual es solo un _atajo_ para la combinaci√≥n espec√≠fica de nariz/ment√≥n/boca/ojos que ya est√° en el modelo y que se parece a lo que queremos.

Puedes ver la limitaci√≥n: si a√∫n no est√° en el modelo, no se puede producir mediante una inversi√≥n textual.

Las inversiones textuales siguen siendo muy populares porque se utilizan en indicaciones negativas (un uso com√∫nmente denominado "incrustaci√≥n negativa"). La gente entrena inversiones textuales sobre cosas indeseables como malas manos y mutaciones. Cuando los colocamos en nuestras indicaciones negativas, podemos mejorar casi todas las indicaciones.

## ¬øQu√© pueden hacer los LoRA?

Los LoRA son extremadamente vers√°tiles. A continuaci√≥n se muestran algunos conceptos en los que la comunidad de Stable Diffusion ha capacitado a los LoRA:

- Mejoras de calidad (por ejemplo, [Detail Tweaker](https://civitai.com/models/58390/detail-tweaker-lora-lora) )
- Estilos/est√©tica (p. ej., [estilo Arcano](https://civitai.com/models/7094/arcane-style-lora) , [estilo Studio Ghibli](https://civitai.com/models/6526/studio-ghibli-style-lora) , [Anime Lineart](https://civitai.com/models/16014/anime-lineart-manga-like-style) )
- Personajes o personas (por ejemplo, [Makima](https://civitai.com/models/5373/makima-chainsaw-man-lora) , [Cute_girl_mix](https://civitai.com/models/14171/cutegirlmix4) )
- Ropa u objetos (por ejemplo, [Hanfu](https://civitai.com/models/15365/hanfu) , [Foo taiwan√©s](https://civitai.com/models/21079/common-taiwanese-food-or) )
- Entornos (por ejemplo, [edificio escolar](https://civitai.com/models/20289/school-building-scenery-lora) )

Las generaciones siguientes utilizan el mismo modelo, el mismo mensaje y la misma semilla. La √∫nica diferencia es la presencia de LoRA:

![[Pasted image 20230924161811.png]]
[Colorwater](https://civitai.com/models/16055/colorwater) 

![[Pasted image 20230924161832.png]]
[Hanfu](https://civitai.com/models/15365/hanfu)

![[Pasted image 20230924161848.png]]
[Anime Lineart](https://civitai.com/models/16014/anime-lineart-manga-like-style)

**Puede utilizar LoRA con cualquier modelo de Stable Diffusion** , siempre que el modelo y LoRA formen parte de la misma serie:

- Los LoRA entrenados desde SD v1.x solo funcionar√°n con modelos entrenados desde SD v1.x
- Los LoRA entrenados desde SD v2.x solo funcionar√°n con modelos entrenados desde SD v2.x
- Los LoRA entrenados desde SDXL solo funcionar√°n con modelos entrenados desde SDXL

Generalmente, los LoRA realistas funcionan mejor con modelos realistas y los LoRA de anime funcionan mejor con modelos de anime. Sin embargo, esta distinci√≥n no es tan clara, ya que los modelos m√°s populares hoy en d√≠a son **fusiones** de modelos realistas y anime/estilizados.

A veces, los creadores suelen tener notas sobre los modelos recomendados en sus descripciones de LoRA.

## ¬øD√≥nde descargas los LoRA?
Hay 2 lugares para encontrar LoRA:

- [**Civitai.com**](https://civitai.com/tag/lora) : M√°s popular y recomendado
- [**HuggingFace.co**](https://huggingface.co/lora-library) : Menos popular. El problema es que HuggingFace coloca a los LoRA en la misma categor√≠a que los modelos de punto de control, por lo que no hay una manera f√°cil de encontrarlos.

No entrar√© en detalles sobre NSFW LoRA, pero hay _muchos_ en Civitai, solo tienes que crear una cuenta para verlos.

## LoRA populares

### LoRA de prop√≥sito general

Los LoRA se pueden utilizar para mejorar la calidad de la imagen o producir variaciones interesantes de una imagen.

- [epinoiseoffset](https://civitai.com/models/13941/epinoiseoffset) : aumenta el contraste para obtener im√°genes de mejor calidad. **Recomendado üî•**
- [Detail Tweaker](https://civitai.com/models/58390/detail-tweaker-lora-lora) : aumenta o disminuye el nivel de detalle. **Recomendado üî•**
- [CharTurnerBeta](https://civitai.com/models/7252/charturnerbeta-lora-experimental) : crea cambios de personajes para el dise√±o de personajes

![[Pasted image 20230924162100.png]]

[Detail Tweaker LoRA](https://civitai.com/models/58390/detail-tweaker-lora-lora) with [Counterfeit model](https://aituts.com/anime-models#counterfeit)

### LoRA de estilo/est√©tica

Producir una determinada est√©tica o estilo art√≠stico.

- [Colorwater](https://civitai.com/models/16055) - estilo acuarela
- [Anime lineart](https://civitai.com/models/16014/anime-lineart-manga-like-style) - estilo lineart / libro de colores
- [Anime tarot card art style](https://civitai.com/models/11177/anime-tarot-card-art-style-lora) : estilo de ilustraci√≥n de cartas de tarot intrincado
- [Blindbox](https://civitai.com/models/25995/blindbox) - estilo chibi 3D
- [Anime Magazine Cover](https://civitai.com/models/18438/anime-magazine-cover) - estilo de portada de revista

![[Pasted image 20230924162205.png]]

### LoRA de personaje/persona

Crea un personaje ficticio o una persona de la vida real.

- [Yae Miko](https://civitai.com/models/8484/yae-miko-or-realistic-genshin-lora) - Genshin Impact
- [Makima](https://civitai.com/models/5373/makima-chainsaw-man-lora) - Chainsaw Man
- [Jinx](https://civitai.com/models/11457/jinx-league-of-legends) - League of Legends

![[Pasted image 20230924162338.png]]

### Costume LoRAs

- [„ÄêCostume„ÄëStraitjacket](https://civitai.com/models/10640/costumestraitjacket) - agrega camisa de fuerza a los personajes
- [Oversized Sweater/hoodie](https://civitai.com/models/52885/oversized-sweaterhoodie)
- [Urban Samurai](https://civitai.com/models/23337/urban-samurai-or-v014-or-clothing-lora) - ropa tecnol√≥gica y katanas

## C√≥mo utilizar LoRA

### Con AUTOMATIC1111

**Requisito previo:** Tiene un AUTOMATIC1111 funcional y actualizado. Aqu√≠ hay instrucciones espec√≠ficas de la plataforma:

- [Instrucciones de la GPU NVIDIA](https://aituts.com/stable-diffusion-on-windows-automatic1111/)
- [Instrucciones de la GPU AMD](https://aituts.com/stable-diffusion-amd/)
- [instrucciones para Mac](https://aituts.com/stable-diffusion-mac-m1/)

Tambi√©n debe tener un modelo de punto de control descargado y colocado en la carpeta `stable-diffusion-webui/models/Stable-diffusion`. Usar√© [Anything V3](https://civitai.com/models/66) en este ejemplo.

1. Descargue el archivo LoRA ( `.pt`o `.safetensor`) y col√≥quelo en la carpeta `stable-diffusion-webui/models/Lora`. Como ejemplo, usar√© [Detail Tweaker](https://civitai.com/models/58390/detail-tweaker-lora-lora) , pero puedes usar cualquier LoRA que quieras.
2. Inicie su WebUI (haga clic `webui-user.bat`).
3. Bajo la `Generate`bot√≥n, haga clic en el `Show Extra Networks`icono. Es un peque√±o icono rosa:

![[Pasted image 20230924162537.png]]

Haga clic en la pesta√±a LoRA. Mostrar√° todos los LoRA en la carpeta. `stable-diffusion-webui/models/Lora`(si no ves nada, haz clic en el icono gris `Refresh` bot√≥n).

Haga clic en el LoRA que desee y la frase clave de LoRA se agregar√° a su mensaje. Puede utilizar tantos LoRA en el mismo mensaje como desee.

![[Pasted image 20230924162609.png]]


Tambi√©n puedes escribir la frase clave LoRA manualmente. Sigue el formato:  
`<lora:LORA-FILENAME:WEIGHT>`

==`LORA-FILENAME`== es el nombre de archivo del modelo LoRA, sin la extensi√≥n de archivo (por ejemplo, no `.safetensor`).

`WEIGHT`es qu√© tan fuerte quieres que sea LoRA. El rango es 0-1; 0 es lo mismo que desactivar el LoRA, 1 es la fuerza m√°xima. Con muchos LoRA, un peso de `1`puede ser abrumador hasta el punto de crear malos resultados, as√≠ que experimente con valores m√°s bajos como `0.5`a `0.8`.

(Detail Tweaker es un poco especial. Va en 2 direcciones y acepta cualquier valor entre -1 y 1. -1 eliminar√° detalles y 1 agregar√° detalles).

**Palabras desencadenantes:** a veces, los LoRA tendr√°n palabras desencadenantes. Son palabras que activan el concepto.

(Nuestro ejemplo Detail Tweaker no tiene palabras desencadenantes. Por otro lado, con un LoRA como **Anime Lineart** , querr√°s incluir " **lineart** " en tu mensaje. El creador generalmente te dir√° estas palabras desencadenantes, si las hay, en la descripci√≥n de LoRA.)

#### Ejemplo

**Escribe el mensaje:**

```
(extremely detailed CG unity 8k wallpaper),(masterpiece), (best quality), (ultra-detailed), (best illustration),(best shadow),(an extremely delicate and beautiful), dynamic angle, floating, finely detail,Depth of field,1girl,solo,girl with beautiful detailed despair face and long fluttering hair and beautiful detailed eyes,((blood)) <lora:add_detail:1>
```

**Y el mensaje negativo:**

```
mutated hands and fingers:1.5,lowres, bad anatomy, bad hands, fused fingers,text error, liquid digit,missing fingers, extra digits,malformed feet, fewer digits, cropped,fused feet,worst quality, low quality, standard quality, jpeg artifacts , signature, watermark, username, blurry,bad mouth,cracked mouth
```

**Establecer la semilla: `3944989649`**

Y luego haga clic `Generate`. Esto es lo que obtengo.

![[Pasted image 20230924162939.png]]

Aseg√∫rese de que sus configuraciones sean todas iguales si est√° intentando seguirlas. estoy usando el `Euler a` dechado, `20` pasos de muestreo y `7` Escala CFG.

¬øC√≥mo puedes saber qu√© est√° haciendo realmente LoRA?

Cambiar `<lora:add_detail:1>`a `<lora:add_detail:0>`(desactivando el LoRA por completo), y luego regenerar.

Entonces cambia esta frase a `<lora:add_detail:-1>`y regenerar (recuerde que la direcci√≥n negativa _elimina_ detalles).

Entonces podemos comparar las generaciones:

![[Pasted image 20230924163209.png]]

Agregar detalles aumenta los detalles, la iluminaci√≥n y las texturas. Por otro lado, eliminar detalles crea una ilustraci√≥n de estilo plano que resulta atractiva a su manera.

## Entrenamiento de LoRA

Se ha **comparado el entrenamiento de LoRA con hornear un pastel** , y esa es la mejor analog√≠a que he visto hasta ahora.

Intentas conseguir los mejores ingredientes (im√°genes de entrenamiento), usas la temperatura adecuada (configuraciones), pero despu√©s de meterlo en el horno (comenzar a entrenar) solo puedes rezar para que todo salga bien.

![[Pasted image 20230924163306.png]]

No tendr√°s idea de si tendr√°s √©xito o no hasta que est√© terminado (aunque puedes [verificar el progreso](https://aituts.com/stable-diffusion-lora/#generating-sample-images) en todo momento).

**Por eso es importante sumergirse y HORNEAR** , en lugar de intentar crear el "LoRA perfecto". ¬°Deber√≠as dedicar m√°s tiempo a hornear y menos a leer!

**Un LoRA fallido le ense√±ar√° mucho m√°s que cualquier gu√≠a que lea.** Utilice los n√∫meros predeterminados a continuaci√≥n y solucione el problema desde all√≠. Es **imposible** predecir por completo qu√© va a hacer la IA, con qu√© elementos va a luchar, c√≥mo aceptar√° las im√°genes dadas, etc.

Lo bueno: cada LoRA que entrenes te brindar√° una mejor intuici√≥n y nuevos conocimientos sobre c√≥mo entrenar mejor al siguiente.

No pretendo que este sea el tren "correcto". Estas son algunas de las mejores pr√°cticas que aprend√≠ al capacitar a alrededor de 40 LoRA.

He escrito una gu√≠a separada para entrenar [SDXL LoRA con Runpod](https://aituts.com/sdxl-lora/) .

Antes de comenzar necesitar√°s:

- **GPU NVIDIA** con al menos 6 GB, pero en realidad 8 GB o m√°s de VRAM (existen soluciones para tarjetas AMD, pero no est√°n maduras)
    - Si no tienes NVIDIA, no tienes suficiente VRAM o simplemente quieres entrenar m√°s r√°pido, puedes usar [Google Colab para tu entrenamiento](https://colab.research.google.com/github/camenduru/kohya_ss-colab/blob/main/kohya_ss_colab.ipynb) .
- **Un modelo fundamental:**
    
    - Muchos (pero no todos) modelos son adecuados como modelo b√°sico/fundamental. Elija un modelo que sea bueno en lo que intenta hacer. M√°s sugerencias de modelos a continuaci√≥n.
    
    - Aqu√≠ hay algunas ideas:
        - Para estilo anime/dibujos animados, elija un [modelo de la familia NAI](https://aituts.com/anime-models#nai) : NAI Diffusion, AnythingV3.0, AnythingV4.0, AnythingV4.5, AnythingV5.
        - Para un estilo realista, elija Stable Diffusion v1.5, o si tiene 12GM VRAM, puede optar por [SDXL](https://aituts.com/sdxl/) .

Esto es lo que haremos:

1. Prepare training images
2. Create folder structure
3. Install Koyha SS
4. Captioning/Tagging
5. Train LoRA

### Paso 1: preparar im√°genes de entrenamiento

Decide cu√°l quieres que sea el tema de tu LoRA antes de comenzar.

Uno de nuestros [suscriptores](https://aituts.com/join/) me envi√≥ un conjunto de datos de Lisa, la artista de K-pop:

![[Pasted image 20230924163527.png]]

Usar√© esto como ejemplo para entrenar un LoRA paso a paso. Aqu√≠ est√°n las im√°genes que LoRA es capaz de producir cuando est√© terminado:

![[Pasted image 20230924163547.png]]

El conjunto de datos tiene 34 im√°genes. Cuantas m√°s im√°genes mejor, pero **la calidad importa** . No agregue im√°genes por agregar im√°genes si son de baja calidad.

Utilice √∫nicamente archivos JPG y PNG. Convierta cualquier imagen WEBP a JPG/PNG antes de comenzar.

Si creas un personaje, aseg√∫rate de que tus im√°genes tengan:

- Poses unicas
- √Ångulos de zoom √∫nicos
- Diferentes trajes
- Colores diferentes
- Mayor resoluci√≥n que 512x512

#### Fuentes de im√°genes

Aqu√≠ hay algunos sitios web √∫tiles para obtener im√°genes:

- [Pinterest](https://www.pinterest.com/) : Excelente por su versatilidad. Probablemente encontrar√°s lo que est√°s buscando.
- [Danbooru](https://danbooru.donmai.us/) : el sitio web booru m√°s grande: la mayor√≠a de los modelos de puntos de control de anime y LoRA obtienen sus im√°genes desde aqu√≠
- [Safebooru](https://safebooru.donmai.us/) : Como Danbooru, pero solo para im√°genes SFW
- [MovieStillsDB](https://www.moviestillsdb.com/) : Archivo de m√°s de 1 mill√≥n de im√°genes fijas de pel√≠culas, con posibilidad de b√∫squeda por actores y t√≠tulo de la pel√≠cula.

### Paso 2: estructura de carpetas

Cree esta estructura de carpetas:

***img***: Esta es la carpeta que contendr√° la carpeta de im√°genes.
Dentro de esta carpeta 'img', crear una subcarpeta siguiendo la convenci√≥n `$REPEATS_TRIGGER CLASS$`.

- ``REPEATS`` es el n√∫mero de pasadas que realizar√° el algoritmo de entrenamiento sobre cada imagen por √©poca. Un buen n√∫mero es 200-400 dividido por la cantidad de im√°genes que tienes, redondeando hacia abajo. Por ejemplo, si tienes 34 im√°genes, $200/34 \approx 6$.

- `TRIGGER` es algo √∫nico que se mencionar√° en su mensaje para que LoRA se aplique correctamente. No usar√© "lisa" porque el modelo podr√≠a interpretarlo como otra cosa.

- `CLASS` es la clase amplia de cosas a las que pertenece su tema. En este caso, usaremos 'woman'.

Entonces, llamar√≠a a mi carpeta `6_lisabp woman`.

¬°No pongas nada m√°s dentro de esta carpeta!

***model***: Esta carpeta es donde se colocar√°n tus modelos finales.

***log*** (opcional): d√≥nde ir√°n tus registros.

***reg*** (opcional): aqu√≠ es donde se colocan las im√°genes de regularizaci√≥n. Esto es opcional, pero muy recomendable. Cree una subcarpeta con el siguiente formato: `1_CLASS`, donde `CLASS` debe ser el mismo que se us√≥ en el nombre de la carpeta de im√°genes arriba. En este ejemplo, usar√≠amos `1_woman`.

Me gusta poner todo en la misma carpeta para mantenerme organizado. Terminar√© con una estructura de carpetas similar a esta:

![[Pasted image 20230924164224.png]]


**Paso 3: Im√°genes de Regularizaci√≥n para Entrenamiento**

Las im√°genes de regularizaci√≥n son *opcionales*, pero pueden mejorar tu entrenamiento. Puedes excluirlas por completo si lo prefieres.

Existen varias formas de obtener im√°genes de regularizaci√≥n. Puedes descargar conjuntos prefabricados desde enlaces como este:

[Conjuntos de Im√°genes de Regularizaci√≥n](https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/tree/main)

En tu caso, utilizar√°s el conjunto de datos "mujer" llamado `woman_v1-5_mse_vae_ddim50_cfg7_n4420.zip`.

Descarga el conjunto de im√°genes que consideres m√°s adecuado para tu tema y descompr√≠melo.

Luego, copia al menos *X* n√∫mero de im√°genes a la subcarpeta que creaste previamente en la carpeta de regularizaci√≥n (en mi caso, se llama `1_woman`). Donde *X* se calcula como REPETICIONES * N√öMERO_DE_IM√ÅGENES_ENTRENAMIENTO.

En nuestro caso, esto significa 6 * 34 = 204 im√°genes.

### Paso 4: Instale Koyha SS

Koyha SS es la mejor interfaz de usuario de su clase para modelos de entrenamiento en este momento.

#### Dependencias requeridas

- Instalar [Python 3.10](https://www.python.org/ftp/python/3.10.9/python-3.10.9-amd64.exe)
    - aseg√∫rese de marcar la casilla para agregar Python a la variable de entorno 'PATH'
- Instalar [Git](https://git-scm.com/download/win)
- Instale [Visual Studio 2015, 2017, 2019 y 2022 redistribuible](https://aka.ms/vs/17/release/vc_redist.x64.exe)

Abra una ventana del s√≠mbolo del sistema (en la barra de b√∫squeda, busque "s√≠mbolo del sistema", haga clic en S√≠mbolo del sistema).

En el s√≠mbolo del sistema, navegue hasta donde desea instalar Kohya.

Utilice este comando para moverse a la carpeta (presione `Enter`para ejecutarlo):

```
cd FOLDER_NAME
```

Utilice este comando para hacer una copia de seguridad de una carpeta:

```
cd ..
```

Utilice este comando para enumerar todas las carpetas dentro de la carpeta en la que se encuentra. Esto puede ayudarle a orientarse:

```
dir
```

Como ejemplo, instalar√© Koyha en mi `Documents` carpeta. Yo escribir√≠a este comando:

```
cd documents
```

![[Pasted image 20230924164534.png]]

Copie y pegue cada l√≠nea, una por una, y presione Entrar.

```
clon de git https://github.com/bmaltais/kohya_ss.git
 cd kohya_ss
 .\setup.bat
```

Ingrese 1 y luego 1 para las opciones:

![[Pasted image 20230924164633.png]]

**Nota: la instalaci√≥n completa de los paquetes puede tardar un poco.**

Cuando se complete la instalaci√≥n, ingrese `4`, que es la opci√≥n de `Start Kohya_ss GUI in browser`.

En unos segundos deber√≠a darte el mensaje de √©xito:

`Running on local URL: http://127.0.0.1:7860`

Vaya a esta URL en su navegador web [http://127.0.0.1:7860](http://127.0.0.1:7860) para abrir la interfaz:

![[Pasted image 20230924164705.png]]

### Step 5: Caption Images
Cada imagen de tus datos de entrenamiento necesita un t√≠tulo correspondiente, o un `.txt`archivos que describen el contenido de la imagen.

**Afortunadamente, Koyha tiene una herramienta incorporada para reconocer y subtitular im√°genes autom√°ticamente** .

Nos ayudar√° a subtitular con oraciones en lenguaje natural como: " `girl with yellow dress sitting down`", as√≠ como etiquetas divididas por comas como " `1girl, yellow dress, sitting`". El estilo de los subt√≠tulos depende de si el tema es realista o anime/estilizado.

#### Para sujetos realistas

Clickea en  `Utilities` pesta√±a -> `Captioning` pesta√±a -> `BLIP Captioning` pesta√±a.

En `Image folder to caption`, selecciona la carpeta con tus im√°genes de entrenamiento.

![[Pasted image 20230924164854.png]]

Para la configuraci√≥n:

1. **`Prefix to add to BLIP caption`**_:_ agregue la palabra desencadenante elegida, **seguida de** una coma y un espacio. En nuestro caso 'lisabp, '
2. **`Batch size`**_:_ Mant√©ngase en 1-2, a menos que tenga una GPU con mayor VRAM.
3. **`Use beam search`**_:_ Comprobado
4. **`Number of beams`**_:_ aumentar esta configuraci√≥n produce subt√≠tulos m√°s coherentes tipo "oraci√≥n". Establezca esto entre 10 y 15.
5. **`Min length`**_:_ Establezca esto en 25-30; de lo contrario, los subt√≠tulos ser√°n demasiado cortos.

Golpear " `Caption Images`". La primera vez que haga esto, tardar√° un poco en descargar el subt√≠tulo BLIP. Consulte el s√≠mbolo del sistema para ver las actualizaciones de estado.

Una vez finalizados los subt√≠tulos, la herramienta colocar√° autom√°ticamente los archivos de subt√≠tulos en la misma carpeta que sus im√°genes de entrenamiento.

#### Para anime/sujetos estilizados

Los temas de anime requieren un estilo de subt√≠tulos diferente.

Clickea en el `Utilities` pesta√±a -> `Captioning` pesta√±a -> `WD14 Captioning`pesta√±a.

En `Image folder to caption`, selecciona la carpeta con tus im√°genes de entrenamiento.

Si est√°s entrenando un estilo LoRA, puedes dejar la configuraci√≥n predeterminada. Si entrenas a un personaje LoRA cambia el `Character Threshold` ajuste a `0.7`

![[Pasted image 20230924165024.png]]

Golpear " `Caption Images`". La primera vez que haga esto, tardar√° un poco en descargar el subt√≠tulo Blip. Consulte el s√≠mbolo del sistema para ver las actualizaciones de estado.

Una vez finalizados los subt√≠tulos, la herramienta colocar√° autom√°ticamente los archivos de subt√≠tulos en la misma carpeta que sus im√°genes de entrenamiento.

![[Pasted image 20230924165102.png]]

### Paso 6: Entrenamiento

¬°Finalmente est√°s listo para entrenar!

**Aseg√∫rate de cambiar a la pesta√±a `LoRA`  y no estar en la pesta√±a `Dreambooth` .** Esto ha causado mucha confusi√≥n porque el contenido de las pesta√±as parece el mismo.

![[Pasted image 20230924165231.png]]

#### Selecci√≥n de modelo

Seleccione el modelo fundamental (base) en el que entrenar√° su LoRA.

`Model Quick Pick`le permitir√° utilizar los modelos base de StabilityAI y sus socios:

![[Pasted image 20230924165258.png]]

Si seleccionas `custom`, puedes elegir un modelo que hayas descargado.

![[Pasted image 20230924165314.png]]

Otras opciones:

- **`v2`casilla de verificaci√≥n** : marque la casilla de verificaci√≥n v2 si est√° utilizando Stable Diffusion v2.0 o v2.1 como base, o un modelo ajustado a partir de estos.
- **`SDXL Model`casilla de verificaci√≥n** : Marque la casilla de verificaci√≥n Modelo SDXL si est√° utilizando SDXL v1.0 como base o un modelo ajustado desde SDXL. **Esto requiere un m√≠nimo de 12 GB de VRAM** . Si no tienes suficiente VRAM, prueba Google Colab.

Los modelos base funcionan bien; A veces, los modelos personalizados funcionar√°n mejor. Aqu√≠ te dejo algunos modelos que recomiendo para entrenar:

- **[NeverEnding Dream](https://aituts.com/models#neverending-dream)** ¬† : gran modelo para el entrenamiento de personajes y temas espec√≠ficos (BLIP o WD14 funcionan)
- **[Anything V5](https://aituts.com/models#anything-v5)** ¬† : Anything V3 inici√≥ una generaci√≥n de LoRA de anime. Esta es la pr√≥xima versi√≥n del mismo autor. (Subt√≠tulos WD14)
- **[ReV Animated](https://aituts.com/models#rev-animated)** ¬† : un modelo confiable y predecible que puede usar como alternativa (BLIP o WD14 funcionan)
- **[AnyLora](https://civitai.com/models/23900)** : modelo creado para entrenar anime LoRA (subt√≠tulos WD14)

#### Archivo de configuraci√≥n

[**Descargue el archivo de configuraci√≥n**](https://pastebin.com/raw/ZgbbrE7f) (Vaya al enlace, luego haga clic derecho en la p√°gina -> `Save as`), luego cambie la extensi√≥n para que el nombre del archivo sea `pastebin.com_raw_ZgbbrE7f.json`

Haga clic en el " `Configuration File`"men√∫ desplegable y luego `Open`.

![[Pasted image 20230924165457.png]]

Seleccione el archivo que acaba de descargar y luego presione `Load`.

#### Establecer carpetas

Ve a la " `Folders`"pesta√±a y configure sus carpetas:

- `Image folder`: ubicaci√≥n de `img` carpeta que cre√≥ en el paso anterior (NO la subcarpeta numerada dentro de ella)
- `Output folder`: carpeta para colocar sus LoRA cuando est√© completo
- `Regularization` `folder` **(opcional)** : ubicaci√≥n de la carpeta de registro que contiene una subcarpeta con sus im√°genes de regularizaci√≥n
- `Logging` `folder`(opcional) : carpeta donde enviar sus registros
- `Model output name`: Nombre de su LoRA generado. Por lo general, me gusta nombrar LoRA con la palabra desencadenante seguida de un n√∫mero de versi√≥n como " `_v1`", en caso de que entrene algunos (la mayor√≠a de las veces, se necesitan varios intentos para hacerlo bien).

![[Pasted image 20230924165626.png]]

#### √âpocas y pasos

Creo que los personajes LoRA salen mejor cuando se entrenan entre 1500 y 3000 pasos.

Hay varias formas de lograrlo, pero primero comprendamos c√≥mo se calculan los pasos:

**pasos totales =** ( **number of images** * **repeats** * **epochs**  * **regularization multiplier** ) / **batch size**

- **==numero de imagenes==** se explica por s√≠ mismo, es la cantidad de im√°genes de entrenamiento que recopil√≥ anteriormente y coloc√≥ en una subcarpeta.
- **==repite==** es el n√∫mero que usamos en el nombre de esta carpeta que contiene nuestras im√°genes de entrenamiento. En mi ejemplo, se trataba de 6_lisabp woman, siendo **6** el n√∫mero de repeticiones.
- **==√©pocas==** es una configuraci√≥n que puedes cambiar en el `Parameters` subpesta√±a. Muestra cu√°ntas pasadas completas realiza el algoritmo de aprendizaje a trav√©s de todo el conjunto de datos de entrenamiento.
- **==multiplicador de regularizaci√≥n==** es 1 o 2. Si no est√° utilizando im√°genes de regularizaci√≥n, este es 1 (no sucede nada). Si est√° utilizando im√°genes de regularizaci√≥n, esto es 2 (los pasos se duplican).
- **==tama√±o del lote==** es una configuraci√≥n que puedes cambiar en el `Parameters` subpesta√±a. Se refiere a cu√°ntas im√°genes se entrenan a la vez.

**Puede utilizar su n√∫mero de im√°genes como punto de partida para calcular estos otros n√∫meros.**

**Las √©pocas** son bastante arbitrarias y en realidad no son necesarias. Son simplemente una forma de dividir su entrenamiento en partes, de modo que pueda generar "modelos de progreso" en cada √©poca durante el proceso de entrenamiento para verificar en qu√© punto su modelo se sobreentrena.

Volvamos a mi ejemplo: tengo 34 im√°genes de lisabp y mi carpeta se llama `**6_lisabp**`. Eso le dice a Kohya que repita cada imagen 6 veces, por lo que con una √©poca obtienes 204 pasos (34 im√°genes * 6 repeticiones = 204 pasos).

Si configuro las √©pocas en 10, ejecutar√© el entrenamiento durante un total de 2040 pasos (34 im√°genes * 6 repeticiones * 10 √©pocas = 2040 pasos), lo que se encuentra dentro de mi rango de pasos √≥ptimo de 1500-3000.

Ahora, ¬øpor qu√© no establecer√≠a mis repeticiones en 60 y mis √©pocas en 1? ¬øNo dar√≠a eso exactamente el mismo resultado? (60 repeticiones * 34 im√°genes * 1 √©poca = 2040 pasos)

**S√≠, lo ser√≠a** . No hay diferencia t√©cnica si entrenamos para 1 repetici√≥n y 100 √©pocas en comparaci√≥n con 100 repeticiones y 1 √©poca.

Sin embargo, en la pr√°ctica hay una gran diferencia. Hay una configuraci√≥n que le permite **generar un modelo en cada √©poca** . Si solo tuvieras una √©poca, solo obtendr√≠as el modelo final. Si tengo 10 √©pocas, obtendr√© 10 versiones del modelo, generadas cada 204 pasos.

Esto me permite probar cada modelo para ver en qu√© punto se entrena mejor y en qu√© punto el modelo se sobreajusta.

Por lo tanto, cuantas menos repeticiones tengamos, m√°s √©pocas podamos tener, m√°s modelos podremos generar a lo largo del proceso de entrenamiento, lo que nos ayudar√° a elegir el mejor n√∫mero real de pasos para entrenar nuestro modelo.

Es por eso que recomend√© ajustar las **repeticiones** para que una sola √©poca tenga entre 200 y 400 pasos. Esto le permitir√° tener muchos modelos para elegir.
#### ¬°Empezar a entrenar!

Golpear `Train model` y comenzar√° el entrenamiento. En la ventana del s√≠mbolo del sistema, ver√° una barra de progreso:
![[Pasted image 20230924170301.png]]

La capacitaci√≥n durar√° entre 15 minutos y 2 horas, seg√∫n su GPU y el tama√±o de su conjunto de datos.

Una vez finalizado su LoRA, puede usarlos como [se describi√≥ anteriormente en esta gu√≠a](https://aituts.com/stable-diffusion-lora/#usage) con AUTOMATIC1111 WebUI.

Aseg√∫rese de incluir la frase clave LoRA como palabra desencadenante en su mensaje. Como ejemplo:

(Lo m√°s probable es que no quieras establecer el peso en un m√°ximo de 1)

```
lisabp with long black hair golden hour light <lora:lisabp:0.85>
```

![[Pasted image 20230924170342.png]]

Puedes probar tu LoRA con diferentes modelos de puntos de control (incluido el modelo que usaste para entrenarlo). Mucho de esto es aleatorio: algunos LoRA simplemente funcionan mucho mejor con algunos modelos que con otros.

### Configuraci√≥n de Koya
No existen ajustes de entrenamiento "perfectos": los ajustes siempre depender√°n del sujeto y de tus im√°genes.

Profundicemos en los que quiz√°s queramos cambiar:
![[Pasted image 20230924170429.png]]


#### 1. Tama√±o del lote

Cu√°ntas im√°genes se entrenan simult√°neamente.

Los valores m√°s altos aceleran el entrenamiento a costa del uso de VRAM.

Si usted tiene:

- 6-8 GB de VRAM: d√©jelo en 1
- 10 GB: configurado en 2
- 12 GB: configurado en 3

(NOTA: deber√° cambiar la tasa de aprendizaje proporcional al tama√±o del lote, consulte **4** )

#### 2. √âpoca

El n√∫mero de **_√©pocas_** es la cantidad de pases completos que realiza el algoritmo de aprendizaje a trav√©s de todo el conjunto de datos de entrenamiento.

En cada √©poca, el algoritmo revisa todos los datos de entrenamiento y actualiza el LoRA en funci√≥n de la informaci√≥n acumulada.

**_Las repeticiones_** se refieren a cu√°ntas veces se entrena cada imagen individual _dentro de una √©poca_ .

El n√∫mero de repeticiones lo establece el nombre de esta carpeta dentro del imgcarpeta: `**11_lisabp woman**`. Esto significa que tendremos 11 repeticiones por imagen.

Si tengo 34 im√°genes y 11 repeticiones, una √©poca ser√° 34 * 11 = 374 pasos.

Si especifico 8 √©pocas, entrenar√© en un total de 8 * 374 = 2958 pasos.

**M√°s √©pocas** suelen producir mejores resultados.

Recomiendo no exceder los 3500 **pasos totales** para un LoRA.

##### **Guardar cada n √©pocas**

Esta es una excelente manera de generar modelos a mitad de camino durante la capacitaci√≥n.

A veces los modelos entrenados en demasiados pasos quedan _demasiado cocidos_ .

Es posible que el modelo que desee no sea el modelo final, sino uno de los anteriores.

Si tengo 986 pasos por √©poca, 3 √©pocas, y configuro mi `Save every n epoch`a 1, obtendr√© 3 modelos entrenados en 986, 1972 y 2958 pasos.

#### 3. Precisi√≥n mixta/Guardar precisi√≥n

**Precisi√≥n mixta** : bf16 entrena m√°s r√°pido que fp16, pero solo funciona en GPU 30XX y 40XX.

Sin embargo , mantenga siempre **Guardar precisi√≥n** como fp16.

#### 4. Tasa de aprendizaje/Tasa de aprendizaje del codificador de texto/Tasa de aprendizaje Unet

Debe ajustar estos tres par√°metros de acuerdo con el tama√±o de su lote. Ser√°n el tama√±o de su lote dividido por 1000.  
Ejemplo: tama√±o de lote de **3**

- Tasa de aprendizaje: **0,0003**
- Tasa de aprendizaje del codificador de texto: **0,0003**
- Tasa de aprendizaje unet: **0,0003**

#### 5. Optimizador

En GPU 10XX, no podr√°s usar AdamW8bit

En su lugar, cambie esto a AdamW

#### 6. Rango de red (dimensi√≥n) / Alfa de red

Generalmente, es mejor mantener el rango de red (dimensi√≥n) y el alfa de red iguales.

Para los LoRA de estilo, 256 es un buen n√∫mero para usar tanto para Network Rank como para Network Alpha.

Los personajes LoRA no necesitar√°n m√°s de 128 tanto para Network Rank como para Network Alpha.

#### 7. Resoluci√≥n m√°xima

Si tienes una gran cantidad de VRAM, puedes entrenar con una resoluci√≥n m√°s alta, como 768x768. De lo contrario, d√©jelo en 512x152.

### Generando im√°genes de muestra

Puede optar por generar muestras cada X n√∫mero de pasos en `Sample images config`

![[Pasted image 20230924170806.png]]

Cuanto m√°s frecuentemente hagas muestras, m√°s lento se entrenar√° LoRA. Sin embargo, esta es una buena manera de ver si LoRA va como usted desea.

Generalmente, una muestra cada 200-400 pasos es adecuada para medir el progreso del entrenamiento.

Simplemente incluya un mensaje de muestra relevante seguido de:

```
--n low quality, worst quality, bad anatomy, --w 512 --h 512 --d 1 --l 7.5 --s 20
```

Las muestras se generar√°n dentro de una carpeta dentro del directorio de salida que especific√≥ anteriormente.

(Nota: muchas muestras, especialmente las primeras, pueden resultar distorsionadas, esto es normal)

## Otras lecturas

Civitai. "[Making a LoRA is like baking a cake](https://civitai.com/articles/138/making-a-lora-is-like-baking-a-cake), https://civitai.com/articles/138/making-a-lora-is-like-baking-a-cake."

Zoomy Izumi. "[My Lora Experiment Part 4](https://www.zoomyizumi.com/my-lora-experiment-part-4/), https://www.zoomyizumi.com/my-lora-experiment-part-4/."


## Preguntas m√°s frecuentes

****¬øCu√°ntas im√°genes necesito?**  


Se recomienda tener entre 30 y 150 im√°genes bien etiquetadas, aunque puedes crear un LoRA perfectamente √∫til con tan solo 10 im√°genes.  

****¬øNecesito recortar im√°genes?**  


No, se pueden entrenar im√°genes de cualquier relaci√≥n de aspecto y tama√±o, el script cambia su tama√±o autom√°ticamente y las entrena de manera que conserve su relaci√≥n de aspecto. Algunos utilizan [herramientas de recorte de im√°genes masivas](https://www.birme.net/?target_width=512&target_height=512) para hacer que sus datos de entrenamiento sean cuadrados uniformes, pero es en gran medida redundante y puede recortar partes importantes de la imagen.  

****¬øQu√© define las "im√°genes de alta calidad"?**  


Para un personaje, debe haber una variaci√≥n saludable de √°ngulos, poses y vestimenta.  
Debe ser una mezcla de im√°genes est√°ticas y din√°micas, con fondos m√°s simples y un solo sujeto. No debes tener objetos complejos; debes evitar que el sujeto sostenga objetos.  
  
Los subt√≠tulos son los reyes: 50 im√°genes bien etiquetadas generar√°n un LoRA mejor que 150 im√°genes mal etiquetadas.

****¬ø Cu√°nto tiempo** tardan los LoRA **en entrenarse?**  


Con esta configuraci√≥n, puede tardar entre 15 minutos y aproximadamente 2 horas como m√°ximo, dependiendo de su GPU.




















































___
%%
V√≠nculos:
[[000-Men√∫ Stable Diffusion XL üìÉ|Men√∫ Stable diffusion XL]]

tags:
#pagstable_diffusion_xl #stable_diffusion_xl #stable_diffusion 
%%